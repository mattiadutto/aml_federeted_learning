Motivated by the expansion of computing power, network capacity, coupled with rising concerns about users' data privacy, recent years showed a growth of Federating Learning (FL), a distributed learning approach that offloads training to the user devices where the data resides. From the original introduction of the first federated learning approach, FedAvg, several variations have emerged, each addressing different issues of the federated framework. In this paper, we analyze the performance of FedAvg and one of its most recent evolutions, FedDyn, which promises faster convergence rate.

Work done by Mattia Dutto s287598 (s287598@studenti.polito.it), Simone Alberto Peirone s286886 (s286886@studenti.polito.it) and Nolan Zerigue s293622 (s293622@studenti.polito.it) from Computer Engineering, Politecnico di Torino for the exam of 01URWOV - Advanced Machine Learning 2021/2022 as the final project. 

In this repo you can find four different files:
- centralized.ipynb: starting model, used for the ablation study
- fed-avg.ipynb: federated averaging algorithm the main focus of this project
- fed-dyn.ipynb: federated dynamic an improvement of fed-avg algorithm
- plots.ipynb: to generate all the plots that are present on the paper