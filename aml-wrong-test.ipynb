{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRyFWIxiPEVX"
      },
      "source": [
        "# Baseline implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g_93F5EBC_sY"
      },
      "outputs": [],
      "source": [
        "# download the Cifar10 non-iid splits, if not present\n",
        "\n",
        "from os import path\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "if not path.exists(\"cifar10\"):\n",
        "    save_path = \"cifar10.zip\"\n",
        "    urllib.request.urlretrieve(\"http://storage.googleapis.com/gresearch/federated-vision-datasets/cifar10.zip\", save_path)\n",
        "    \n",
        "    with zipfile.ZipFile(save_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ESEol324C_sa"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"E\": 1, # number of local epochs\n",
        "    \"K\": 1, # number of clients selected each round\n",
        "    \"NUMBER_OF_CLIENTS\": 1, # total number of clients\n",
        "    \"MAX_TIME\": 100,\n",
        "    \"BATCH_SIZE\": 50,\n",
        "    \"LR\": 0.001,\n",
        "    \"DATA_DISTRIBUTION\": \"iid\", # \"iid\" | \"non-iid\"\n",
        "    #\"DIRICHELET_ALPHA\": 0.00, # 0.00, 0.05, 0.10, 0.20, 0.50, 1.00, 10.00, 100.0\n",
        "    #\"LR_DECAY\": 0.99,\n",
        "    \"WEIGHT_DECAY\": 1e-3 #,\n",
        "    #\"LOG_FREQUENCY\": 100,\n",
        "    #\"TRANSFORM_CROP\": 24,\n",
        "    #\"TRANSFORM_RND_HFLIP_PROB\": 0.25,\n",
        "    #\"TRANSFORM_BRIGHTNESS\": 0.5,\n",
        "    #\"TRANSFORM_CONTRAST\": 0.5,\n",
        "    #\"TRANSFORM_SATURATION\": 0.5,\n",
        "    #\"TRANSFORM_HUE\": 0.5\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FByBT_vlC_sc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ar1b6p68b3G",
        "outputId": "1b43264e-5c0f-4442-bb54-24e2f3dbcb68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=1600, out_features=384, bias=True)\n",
            "  (fc2): Linear(in_features=384, out_features=192, bias=True)\n",
            "  (fc3): Linear(in_features=192, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# From: https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, *, input_size=32):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "        self.conv1 = nn.Conv2d(3, 64, 5)\n",
        "        self.conv2 = nn.Conv2d(64, 64, 5)\n",
        "        \n",
        "        # output of the conv layer is (w', h') = (w - 5 + 1, h - 5 + 1)\n",
        "        # max_pool2d halves the dimensions (w', h') = (w / 2, h / 2)\n",
        "\n",
        "        # dynamically compute the image size\n",
        "        size = input_size // 4 - 3\n",
        "        self.fc1 = nn.Linear(64 * (size * size), 384)\n",
        "        self.fc2 = nn.Linear(384, 192)\n",
        "        self.fc3 = nn.Linear(192, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square, you can specify with a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net = net.to(device)\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eCwGFjE5Feil"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "class Client():\n",
        "  def __init__(self, i, train_set, validation_set, *, input_size=32):\n",
        "    self.i = i\n",
        "    self.train_loader = torch.utils.data.DataLoader(train_set, batch_size=config[\"BATCH_SIZE\"],\n",
        "                                         shuffle=True, num_workers=0)\n",
        "    self.validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=config[\"BATCH_SIZE\"],\n",
        "                                         shuffle=False, num_workers=0)\n",
        "    self.net = Net(input_size=input_size)\n",
        "    self.net = self.net.to(device)\n",
        "    # create your optimizer\n",
        "    self.optimizer = optim.SGD(self.net.parameters(), lr=config[\"LR\"], momentum = 0.9, weight_decay = config[\"WEIGHT_DECAY\"])\n",
        "    self.criterion = nn.CrossEntropyLoss()\n",
        "    # wandb.watch(self.net, criterion=self.criterion, log_freq=100, log_graph=False)\n",
        "    \n",
        "  def clientUpdate(self, lr, parameters):\n",
        "    self.net.load_state_dict(parameters)\n",
        "    for g in self.optimizer.param_groups:\n",
        "      g['lr'] = lr\n",
        "\n",
        "    for e in range(config[\"E\"]):\n",
        "      for images, labels in self.train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # in your training loop:\n",
        "        self.optimizer.zero_grad()   # zero the gradient buffers\n",
        "        output = self.net(images)\n",
        "        loss = self.criterion(output, labels)\n",
        "        loss.backward()\n",
        "        # wandb.log({f\"client-loss-{self.i}\": loss.item()})\n",
        "        self.optimizer.step()    # Does the update\n",
        "    \n",
        "    return_dict = {}\n",
        "    for (k1, v1), (k2, v2) in zip(parameters.items(), self.net.state_dict().items()):\n",
        "      return_dict[k1] = v1 - v2\n",
        "    return return_dict\n",
        "\n",
        "  def compute_accuracy(self, parameters):\n",
        "    self.net.load_state_dict(parameters)\n",
        "\n",
        "    running_corrects = 0\n",
        "    n = 0\n",
        "    for data, labels in self.validation_loader:\n",
        "        data = data.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = self.net(data)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        n += len(preds)\n",
        "\n",
        "                \n",
        "    return running_corrects / n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QcsNecZCVPP-"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def parse_csv(filename):\n",
        "  splits = defaultdict(lambda: [])\n",
        "  with open(filename) as f:\n",
        "    for line in f:\n",
        "      if not line[0].isdigit():\n",
        "        continue\n",
        "\n",
        "      user_id, image_id, _ = (int(token) for token in line.split(\",\"))\n",
        "      splits[user_id].append(image_id)\n",
        "\n",
        "  return splits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "d55e41200e9a4eeeb909d1fce0bdff22",
            "cb2635bd49d54e12ad3b70b5ad11f3b5",
            "0c34e08232594a5ab01a399d436bb9fd",
            "24daf0c7ec434a61bf6b468d79725296",
            "b294b586f3b24614a2880c54b3401be9",
            "573203903fc8406c8b8748445bc0fbe1",
            "3bcde6e5d24642fa8fa0af6d9ff89674",
            "89aa53fb1f00478e947150d89dd0bf0f",
            "eed6b5acd9dd4ba3ad1982db8c22ed93",
            "a2a8ab9c048b44f880405deab014910c",
            "c6b73c8cb7dd48c18a1d6125d4a161df"
          ]
        },
        "id": "gTmw78eJ-EW5",
        "outputId": "d3b126de-e9a6-45df-af70-a9d5cc6cfab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d55e41200e9a4eeeb909d1fce0bdff22",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import random\n",
        "from statistics import mean\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "     #transforms.RandomCrop(config[\"TRANSFORM_CROP\"]),\n",
        "     #transforms.RandomHorizontalFlip(config[\"TRANSFORM_RND_HFLIP_PROB\"]),\n",
        "     #transforms.ColorJitter(brightness=config[\"TRANSFORM_BRIGHTNESS\"]),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  #transforms.CenterCrop(config[\"TRANSFORM_CROP\"]),\n",
        "  #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=train_transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=test_transform)\n",
        "\n",
        "\n",
        "if config[\"DATA_DISTRIBUTION\"] == \"iid\":\n",
        "  # split the training set\n",
        "  trainset_len = ( len(trainset) // config[\"NUMBER_OF_CLIENTS\"] ) * config[\"NUMBER_OF_CLIENTS\"]\n",
        "  trainset = torch.utils.data.Subset(trainset, list(range(trainset_len)))\n",
        "\n",
        "  lengths = len(trainset) // config[\"NUMBER_OF_CLIENTS\"] * np.ones(config[\"NUMBER_OF_CLIENTS\"], dtype=int)\n",
        "  trainsets = torch.utils.data.random_split(dataset=trainset, lengths=lengths)\n",
        "else:\n",
        "  dirichelet_splits = parse_csv(f\"cifar10/federated_train_alpha_{config['DIRICHELET_ALPHA']:.2f}.csv\")\n",
        "  trainsets = [torch.utils.data.Subset(trainset, indices) for indices in dirichelet_splits.values()]\n",
        "\n",
        "\n",
        "# split the validation set\n",
        "testset_len = ( len(testset) // config[\"NUMBER_OF_CLIENTS\"] ) * config[\"NUMBER_OF_CLIENTS\"]\n",
        "testset = torch.utils.data.Subset(testset, list(range(testset_len)))\n",
        "\n",
        "lengths = len(testset) // config[\"NUMBER_OF_CLIENTS\"] * np.ones(config[\"NUMBER_OF_CLIENTS\"], dtype=int)\n",
        "testsets = torch.utils.data.random_split(dataset=testset, lengths=lengths)\n",
        "\n",
        "\n",
        "clientsSizes = torch.zeros(config[\"NUMBER_OF_CLIENTS\"])\n",
        "clients = list()\n",
        "\n",
        "def selectClients(k):\n",
        "  return random.choices(clients, k=k)\n",
        "\n",
        "def aggregateClient(deltaThetas):\n",
        "  parameters = None\n",
        "  for i,d in enumerate(deltaThetas):\n",
        "    #ratio = len(trainsets[i])/len(trainset)\n",
        "    ratio = len(trainsets[i])/(len(trainsets[i])*config['K'])\n",
        "    \n",
        "    if i == 0:\n",
        "      parameters = {k:ratio*v for k, v in d.items()}\n",
        "    else:\n",
        "      for (k, v) in d.items():\n",
        "        parameters[k] += ratio * v\n",
        "   \n",
        "  return parameters\n",
        "\n",
        "for c in range(config[\"NUMBER_OF_CLIENTS\"]):\n",
        "  clients.append(Client(c, trainsets[c], testsets[c]))#, input_size=config[\"TRANSFORM_CROP\"]))\n",
        "\n",
        "# if config[\"FED_AVG_M\"]:\n",
        "#   old_parameters = {}\n",
        "\n",
        "# initial learning rate\n",
        "lr = config[\"LR\"]\n",
        "\n",
        "# collect the test accuracies over the epochs\n",
        "test_accuracies = []\n",
        "\n",
        "for step in tqdm(range(config[\"MAX_TIME\"])):\n",
        "#for t in range(MAX_TIME):\n",
        "  selected_clients = selectClients(config[\"K\"])\n",
        "  #print(f\"Client(s) {[client.i for client in selected_clients]} selected\")\n",
        "\n",
        "  deltaThetas = list()\n",
        "  for i, c in enumerate(selected_clients):\n",
        "    deltaThetas.append(c.clientUpdate(lr, net.state_dict()))\n",
        "    \n",
        "  g = aggregateClient(deltaThetas)\n",
        "  \n",
        "  parameters = {}\n",
        "  for (k1, v1), (k2, v2) in zip(net.state_dict().items(), g.items()):\n",
        "    \n",
        "    # if config[\"FED_AVG_M\"]:\n",
        "    #   if k1 in old_parameters:\n",
        "    #     parameters[k1] = v1 - config[\"FED_AVG_M_GAMMA\"] * (config[\"FED_AVG_M_BETA\"] * old_parameters[k1] + v2)  \n",
        "    #     old_parameters[k1] = config[\"FED_AVG_M_BETA\"] * old_parameters[k1] + v2\n",
        "    #   else:\n",
        "    #     parameters[k1] = v1 - config[\"FED_AVG_M_GAMMA\"] * v2\n",
        "    #     old_parameters[k1] = v2\n",
        "        \n",
        "    # else:\n",
        "    parameters[k1] = v1 - v2 # todo: add server learning rate gamma\n",
        "\n",
        "  net.load_state_dict(parameters)\n",
        "\n",
        "  # lr *= config[\"LR_DECAY\"]\n",
        "\n",
        "  # if step % config[\"LOG_FREQUENCY\"] == 0:\n",
        "  #   model_parameters = net.state_dict()\n",
        "  #   avg_accuracy = mean(client.compute_accuracy(model_parameters) for client in clients)\n",
        "  #   test_accuracies.append(avg_accuracy)\n",
        "\n",
        "  #   print(f\"Average accuracy after {step} rounds is {avg_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utb7E9snmQwi",
        "outputId": "5205b83b-d2cf-4d27-fda1-3c3aca986091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy after 100 rounds is 0.4697\n"
          ]
        }
      ],
      "source": [
        "from statistics import mean\n",
        "\n",
        "model_parameters = net.state_dict()\n",
        "avg_accuracy = mean(client.compute_accuracy(model_parameters) for client in clients)\n",
        "test_accuracies.append(avg_accuracy)\n",
        "\n",
        "print(f\"Average accuracy after {config['MAX_TIME']} rounds is {avg_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v72-yQubC_sh"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import json\n",
        "\n",
        "timestr = time.strftime(\"%Y_%m_%d-%I_%M_%S_%p\")\n",
        "artifact_filename = f\"artifacts/server_model-{timestr}\"\n",
        "\n",
        "# parameters of the trained model\n",
        "server_model = net.state_dict()\n",
        "# save the model on the local file system\n",
        "torch.save(server_model, artifact_filename + \".pth\")\n",
        "\n",
        "data = {\n",
        "    \"config\": config,\n",
        "    \"test_accuracies\": test_accuracies\n",
        "}\n",
        "\n",
        "with open(artifact_filename + \".json\", \"w\") as f:\n",
        "    f.write(json.dumps(data, indent=4))\n",
        "\n",
        "# save the model on wandb\n",
        "# wandb.save(artifact_filename)\n",
        "# Finish the wandb session and upload all data\n",
        "# wandb.finish(0, quiet=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "aml.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d55e41200e9a4eeeb909d1fce0bdff22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cb2635bd49d54e12ad3b70b5ad11f3b5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0c34e08232594a5ab01a399d436bb9fd",
              "IPY_MODEL_24daf0c7ec434a61bf6b468d79725296",
              "IPY_MODEL_b294b586f3b24614a2880c54b3401be9"
            ]
          }
        },
        "cb2635bd49d54e12ad3b70b5ad11f3b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c34e08232594a5ab01a399d436bb9fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_573203903fc8406c8b8748445bc0fbe1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3bcde6e5d24642fa8fa0af6d9ff89674"
          }
        },
        "24daf0c7ec434a61bf6b468d79725296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_89aa53fb1f00478e947150d89dd0bf0f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eed6b5acd9dd4ba3ad1982db8c22ed93"
          }
        },
        "b294b586f3b24614a2880c54b3401be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a2a8ab9c048b44f880405deab014910c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [17:38&lt;00:00, 10.62s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c6b73c8cb7dd48c18a1d6125d4a161df"
          }
        },
        "573203903fc8406c8b8748445bc0fbe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3bcde6e5d24642fa8fa0af6d9ff89674": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89aa53fb1f00478e947150d89dd0bf0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eed6b5acd9dd4ba3ad1982db8c22ed93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2a8ab9c048b44f880405deab014910c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c6b73c8cb7dd48c18a1d6125d4a161df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}