{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRyFWIxiPEVX"
   },
   "source": [
    "# Baseline implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7iCHpO-d0SR",
    "outputId": "186179ce-3045-4743-ac31-ceae787c248e"
   },
   "outputs": [],
   "source": [
    "!wget http://storage.googleapis.com/gresearch/federated-vision-datasets/cifar10.zip\n",
    "!unzip cifar10.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ww5uiZ6HfmBd"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"E\": 5, # number of local epochs\n",
    "    \"K\": 5, # number of clients selected each round\n",
    "    \"NUMBER_OF_CLIENTS\": 100, # total number of clients\n",
    "    \"MAX_TIME\": 50,\n",
    "    \"BATCH_SIZE\": 10,\n",
    "    \"LR\": 0.25,\n",
    "    \"DATA_DISTRIBUTION\": \"iid\", # \"iid\" | \"non-iid\"\n",
    "    \"DIRICHELET_ALPHA\": 0.00, # 0.00, 0.05, 0.10, 0.20, 0.50, 1.00, 10.00, 100.0\n",
    "    \"FED_AVG_M\": False,\n",
    "    \"FED_AVG_M_BETA\": 0.9,\n",
    "    \"FED_AVG_M_GAMMA\": 1,\n",
    "    \"LR_DECAY_STEP_SIZE\": 1,\n",
    "    \"LR_DECAY\": 0.99,\n",
    "    \"LOG_FREQUENCY\": 5,\n",
    "    \"TRANSFORM_RND_HFLIP_PROB\": 0.5,\n",
    "    \"TRANSFORM_BRIGHTNESS\": 0.5,\n",
    "    \"TRANSFORM_CONTRAST\": 0.0,\n",
    "    \"TRANSFORM_SATURATION\": 0.0,\n",
    "    \"TRANSFORM_HUE\": 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Ar1b6p68b3G"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# From: https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(3, 64, 5)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(1600, 384)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(384, 192)\n",
    "        self.fc3 = nn.Linear(192, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "seEKXjiixeCq"
   },
   "outputs": [],
   "source": [
    "class BatchedNet(nn.Module):\n",
    "    def __init__(self, P, *, const_init=None):\n",
    "        super(BatchedNet, self).__init__()\n",
    "\n",
    "        self.P = P\n",
    "\n",
    "        # convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3 * self.P, 64 * self.P, 5, groups=self.P)\n",
    "        self.conv2 = nn.Conv2d(64 * self.P, 64 * self.P, 5, groups=self.P)\n",
    "\n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Conv1d(1600 * self.P, 384 * self.P, kernel_size=1, groups=self.P)\n",
    "        self.fc2 = nn.Conv1d(384 * self.P, 192 * self.P, kernel_size=1, groups=self.P)\n",
    "        self.fc3 = nn.Conv1d(192 * self.P, 10 * self.P, kernel_size=1, groups=self.P)\n",
    "\n",
    "        if const_init is not None:\n",
    "            for layer in [self.conv1, self.conv2, self.fc1, self.fc2, self.fc3]:\n",
    "                layer.weight.data.fill_(const_init)\n",
    "                layer.bias.data.fill_(const_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x), inplace=True), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x), inplace=True), 2)\n",
    "\n",
    "        x = x.view(batch_size, -1, 1)\n",
    "        x = F.relu(self.fc1(x), inplace=True)\n",
    "        x = F.relu(self.fc2(x), inplace=True)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from typing import List, OrderedDict\n",
    "\n",
    "\n",
    "def inflate_state_dict(\n",
    "    state_dict: OrderedDict[str, Tensor], inflation_ratio: int\n",
    ") -> OrderedDict[str, Tensor]:\n",
    "    \"\"\"\n",
    "    Generated an inflated state dict for the corresponding batched model.\n",
    "\n",
    "    This function returns a state dictionary whose entries are stacks of\n",
    "    `inflation_ratio` copies of the original values contained in `state_dict`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state_dict: OrderedDict[str, Tensor]\n",
    "        The state dict of a non-batched model\n",
    "\n",
    "    inflation_ratio: int\n",
    "        Number of copies of the parameters to include in the inflated state dict\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    OrderedDict[str, Tensor]\n",
    "        The inflated state dict\n",
    "\n",
    "    \"\"\"\n",
    "    parameters = dict()\n",
    "\n",
    "    for key, params in state_dict.items():\n",
    "        inflated_value = torch.stack([params] * inflation_ratio).flatten(0, 1)\n",
    "\n",
    "        if key.startswith(\"fc\") and key.endswith(\"weight\"):\n",
    "            # in batched models linear layers are converted to Conv1d layers that\n",
    "            # expects weights with one more dimension\n",
    "            inflated_value = torch.unsqueeze(inflated_value, -1)\n",
    "\n",
    "        parameters[key] = inflated_value\n",
    "\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def deflate_state_dict(\n",
    "    state_dict: OrderedDict[str, Tensor], deflation_ratio: int\n",
    ") -> List[OrderedDict[str, Tensor]]:\n",
    "    \"\"\"\n",
    "    Deflate a state_dict that was previously inflated for use in a batched model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state_dict: OrderedDict[str, Tensor]\n",
    "        The inflated state dict.\n",
    "\n",
    "    deflation_ratio: int\n",
    "        Number of state dictionaries to extract\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[OrderedDict[str, Tensor]]\n",
    "        A list of `deflation_ratio` state dicts\n",
    "    \"\"\"\n",
    "    deflated_dicts = [dict() for _ in range(config[\"K\"])]\n",
    "\n",
    "    for key, parameters in state_dict.items():\n",
    "        # for each entry of the state dict\n",
    "\n",
    "        for i, chunk in enumerate(torch.chunk(parameters, deflation_ratio)):\n",
    "            # extract the parameters for client i\n",
    "            if key.startswith(\"fc\") and key.endswith(\"weight\"):\n",
    "                chunk = chunk.squeeze()\n",
    "            deflated_dicts[i][key] = chunk\n",
    "\n",
    "    return deflated_dicts\n",
    "\n",
    "\n",
    "def state_dict_diff(\n",
    "    a: OrderedDict[str, Tensor], b: OrderedDict[str, Tensor], alpha=1.0\n",
    ") -> OrderedDict[str, Tensor]:\n",
    "    \"\"\"\n",
    "    Compute the difference between two state dicts\n",
    "    \"\"\"\n",
    "    return {key: (va - alpha * vb) for (key, va), vb in zip(a.items(), b.values())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCwGFjE5Feil"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class Client:\n",
    "    def __init__(self, i, train_set, validation_set):\n",
    "        self.i = i\n",
    "        self.train_loader = torch.utils.data.DataLoader(\n",
    "            train_set,\n",
    "            batch_size=len(train_set),\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "        self.validation_loader = torch.utils.data.DataLoader(\n",
    "            validation_set, batch_size=config[\"BATCH_SIZE\"], shuffle=False, num_workers=0\n",
    "        )\n",
    "\n",
    "    def compute_accuracy(self, model):\n",
    "        running_corrects = 0\n",
    "        n = 0\n",
    "        for data, labels in self.validation_loader:\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(data)\n",
    "\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
    "            n += len(preds)\n",
    "\n",
    "        return running_corrects / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QcsNecZCVPP-"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def parse_csv(filename):\n",
    "    splits = defaultdict(lambda: [])\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            if not line[0].isdigit():\n",
    "                continue\n",
    "\n",
    "            user_id, image_id, _ = (int(token) for token in line.split(\",\"))\n",
    "            splits[user_id].append(image_id)\n",
    "\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515,
     "referenced_widgets": [
      "1e9d347b655f4baa92b905b57afa346a",
      "4a0e26f46b6b4765a9c64f39af19584a",
      "61601de27b6641f4a32af8e8afe1925d",
      "46263493fc1e462fb2dc5758a5f4520d",
      "64b39222fa26456d940f4d5aa2091d10",
      "40d44046a060465b8c462dd38b1ab90f",
      "9743ce9bf2b9495daf94a45b5a1892c7",
      "5258ca5e78c643dfbb2467ae01d3e5d5",
      "057192c358aa4fd2bbcd7c0e142ac83f",
      "de271fef704c4f89b4549efed5daf3b6",
      "343ff4eb9a7647a19bf2a5b7b0d74a90",
      "25d6469997614e298a5c982b65258355",
      "58331fdef2d1484286d3743c93801951",
      "8086c7228bf44b62b0a454d70e912ef6",
      "2d6524f654134b0f90197d71e2e29112",
      "bb884a5f31ff4c7394cdb564abbb60ce",
      "f25c081635eb4d05b90fd96539504e80",
      "34f1328f26434b01b228e4ab524a7b71",
      "f24d6aa9bdae4e7b8e49af8031164967",
      "a8d41ac06d9e480d994e4a291e426fef",
      "f48bef0609b9476eaa19ca03a6ebb4f4",
      "1eee39395eac4ad1869e3eb59b9b0280"
     ]
    },
    "id": "gTmw78eJ-EW5",
    "outputId": "4df9612c-dc7f-4cbc-bba7-de7725e71694"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "from statistics import mean\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from time import perf_counter_ns\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.CenterCrop(24),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "random_transformations = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(config[\"TRANSFORM_RND_HFLIP_PROB\"]),\n",
    "        transforms.ColorJitter(\n",
    "            config['TRANSFORM_BRIGHTNESS'],\n",
    "            config['TRANSFORM_CONTRAST'],\n",
    "            config['TRANSFORM_SATURATION'],\n",
    "            config['TRANSFORM_HUE']\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "if config[\"DATA_DISTRIBUTION\"] == \"iid\":\n",
    "    # split the training set\n",
    "    trainset_len = (len(trainset) // config[\"NUMBER_OF_CLIENTS\"]) * config[\"NUMBER_OF_CLIENTS\"]\n",
    "    # print(trainset_len)\n",
    "    trainset = torch.utils.data.Subset(trainset, list(range(trainset_len)))\n",
    "\n",
    "    lengths = len(trainset) // config[\"NUMBER_OF_CLIENTS\"] * np.ones(config[\"NUMBER_OF_CLIENTS\"], dtype=int)\n",
    "    # print(lengths)\n",
    "    trainsets = torch.utils.data.random_split(dataset=trainset, lengths=lengths)\n",
    "else:\n",
    "    dirichelet_splits = parse_csv(\n",
    "        f\"cifar10/federated_train_alpha_{config['DIRICHELET_ALPHA']:.2f}.csv\"\n",
    "    )\n",
    "    trainsets = [\n",
    "        torch.utils.data.Subset(trainset, indices)\n",
    "        for indices in dirichelet_splits.values()\n",
    "    ]\n",
    "\n",
    "\n",
    "# split the validation set\n",
    "testset_len = (len(testset) // config[\"NUMBER_OF_CLIENTS\"]) * config[\"NUMBER_OF_CLIENTS\"]\n",
    "# print(testset_len)\n",
    "testset = torch.utils.data.Subset(testset, list(range(testset_len)))\n",
    "\n",
    "lengths = len(testset) // config[\"NUMBER_OF_CLIENTS\"] * np.ones(config[\"NUMBER_OF_CLIENTS\"], dtype=int)\n",
    "# print(lengths)\n",
    "testsets = torch.utils.data.random_split(dataset=testset, lengths=lengths)\n",
    "\n",
    "\n",
    "clientsSizes = torch.zeros(config[\"NUMBER_OF_CLIENTS\"])\n",
    "clients = list()\n",
    "\n",
    "# server reference model\n",
    "reference = Net().to(device)\n",
    "reference.train(False)\n",
    "\n",
    "\n",
    "def selectClients(k):\n",
    "    return random.sample(clients, k=k)\n",
    "\n",
    "\n",
    "def aggregateClient(deltaThetas):\n",
    "    parameters = None\n",
    "    for i, d in enumerate(deltaThetas):\n",
    "        ratio = 1 / config[\"K\"]\n",
    "\n",
    "        if i == 0:\n",
    "            parameters = {k: ratio * v for k, v in d.items()}\n",
    "        else:\n",
    "            for (k, v) in d.items():\n",
    "                parameters[k] += ratio * v\n",
    "\n",
    "    return parameters\n",
    "\n",
    "\n",
    "for c in range(config[\"NUMBER_OF_CLIENTS\"]):\n",
    "    clients.append(Client(c, trainsets[c], testsets[c]))\n",
    "\n",
    "\n",
    "batched_model = BatchedNet(config[\"K\"]).to(device)\n",
    "batched_optimizer = optim.SGD(batched_model.parameters(), lr=config[\"LR\"])\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(\n",
    "    batched_optimizer, step_size=config[\"LR_DECAY_STEP_SIZE\"], gamma=config[\"LR_DECAY\"]\n",
    ")\n",
    "\n",
    "# preload all the training data on the GPU\n",
    "client_images, client_labels = [], []\n",
    "for client in clients:\n",
    "    # take all the images and labels used by the selected client\n",
    "    images, labels = next(iter(client.train_loader))\n",
    "    client_images.append(images.to(device))\n",
    "    client_labels.append(labels.view((-1, 1)).to(device))\n",
    "\n",
    "if config[\"FED_AVG_M\"]:\n",
    "    old_parameters = {}\n",
    "\n",
    "# collect the test accuracies over the epochs\n",
    "test_accuracies = []\n",
    "\n",
    "for step in trange(config[\"MAX_TIME\"]):\n",
    "    selected_clients = selectClients(config[\"K\"])\n",
    "    selected_ids = set(c.i for c in selected_clients)\n",
    "\n",
    "    selected_client_images = [\n",
    "        ci for i, ci in enumerate(client_images) if i in selected_ids\n",
    "    ]\n",
    "    selected_client_labels = [\n",
    "        cl for i, cl in enumerate(client_labels) if i in selected_ids\n",
    "    ]\n",
    "\n",
    "    # randomize the batches\n",
    "    permutations = [\n",
    "        torch.randperm(sci.shape[0], device=device) for sci in selected_client_images\n",
    "    ]\n",
    "    selected_client_images = [\n",
    "        sci[perm] for sci, perm in zip(selected_client_images, permutations)\n",
    "    ]\n",
    "    selected_client_labels = [\n",
    "        scl[perm] for scl, perm in zip(selected_client_labels, permutations)\n",
    "    ]\n",
    "\n",
    "    # apply the transformations\n",
    "    selected_client_images = [\n",
    "        random_transformations(sci) for sci in selected_client_images\n",
    "    ]\n",
    "\n",
    "    # take the parameters of the reference model\n",
    "    reference_parameters = reference.state_dict()\n",
    "    # inflate the state dict to be used in the batched model\n",
    "    batched_model_parameters = inflate_state_dict(reference_parameters, config[\"K\"])\n",
    "    # apply the state dict\n",
    "    batched_model.load_state_dict(batched_model_parameters)\n",
    "\n",
    "    t0 = perf_counter_ns()\n",
    "    for epoch in range(config[\"E\"]):\n",
    "        # for each local epoch\n",
    "\n",
    "        batch_size = config[\"BATCH_SIZE\"]\n",
    "        n_batches = selected_client_images[0].shape[0] // config[\"BATCH_SIZE\"]\n",
    "\n",
    "        for i in range(n_batches):\n",
    "            # for each local batch\n",
    "\n",
    "            batched_optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            # load all the K batches (one batch for each client)\n",
    "            batch_images = [\n",
    "                ci[i * batch_size : (i + 1) * batch_size]\n",
    "                for ci in selected_client_images\n",
    "            ]\n",
    "            batch_labels = (\n",
    "                cl[i * batch_size : (i + 1) * batch_size]\n",
    "                for cl in selected_client_labels\n",
    "            )\n",
    "\n",
    "            # reshape the batches as one tensor of shape [batch_size, K * 3, 32, 32]\n",
    "            # batch_images = torch.stack(batch_images).view((batch_size, -1, 32, 32))\n",
    "            batch_images = torch.stack(batch_images, dim=1).flatten(1, 2)\n",
    "            # print(batch_images.shape)\n",
    "\n",
    "            # compute the batch ouput of the model\n",
    "            # output[:, 10*i:10*(i+1)] is the model output for client i\n",
    "            # shape of output is [10, 100, 1]\n",
    "            output = batched_model(batch_images)\n",
    "\n",
    "            # compute the loss separately for each client\n",
    "            loss = 0\n",
    "            for _output, _labels in zip(torch.chunk(output, config[\"K\"], dim=1), batch_labels):\n",
    "                loss += criterion(_output, _labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # apply the gradient descent step\n",
    "            batched_optimizer.step()\n",
    "\n",
    "    clients_parameters = deflate_state_dict(batched_model.state_dict(), config[\"K\"])\n",
    "    # compute the difference wrt the initial parameters\n",
    "    clients_parameters = [\n",
    "        state_dict_diff(reference_parameters, params) for params in clients_parameters\n",
    "    ]\n",
    "\n",
    "    g = aggregateClient(clients_parameters)\n",
    "\n",
    "    new_parameters = dict()\n",
    "    for (k1, v1), v2 in zip(reference_parameters.items(), g.values()):\n",
    "        if config[\"FED_AVG_M\"]:\n",
    "            if k1 in old_parameters:\n",
    "                new_parameters[k1] = v1 - config[\"FED_AVG_M_GAMMA\"] * (\n",
    "                    config[\"FED_AVG_M_BETA\"] * old_parameters[k1] + v2\n",
    "                )\n",
    "                old_parameters[k1] = config[\"FED_AVG_M_BETA\"] * old_parameters[k1] + v2\n",
    "            else:\n",
    "                new_parameters[k1] = v1 - config[\"FED_AVG_M_GAMMA\"] * v2\n",
    "                old_parameters[k1] = v2\n",
    "        else:\n",
    "            new_parameters[k1] = v1 - v2  # todo: add server learning rate gamma\n",
    "\n",
    "    reference.load_state_dict(new_parameters)\n",
    "\n",
    "    if (step + 1) % config[\"LOG_FREQUENCY\"] == 0:\n",
    "        avg_accuracy = mean(client.compute_accuracy(reference) for client in clients)\n",
    "        test_accuracies.append(avg_accuracy)\n",
    "        print(f\"Average accuracy after {step + 1} rounds is {avg_accuracy}\")\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utb7E9snmQwi"
   },
   "outputs": [],
   "source": [
    "avg_accuracy = mean(client.compute_accuracy(reference) for client in clients)\n",
    "test_accuracies.append(avg_accuracy)\n",
    "print(f\"Average accuracy after {config['MAX_TIME']} rounds is {avg_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4yo5tYPNmxQz"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "timestr = time.strftime(\"%Y_%m_%d-%I_%M_%S_%p\")\n",
    "artifact_filename = f\"artifacts/server_model-{timestr}\"\n",
    "\n",
    "# parameters of the trained model\n",
    "server_model = reference.state_dict()\n",
    "# save the model on the local file system\n",
    "torch.save(server_model, artifact_filename + \".pth\")\n",
    "\n",
    "data = {\n",
    "    \"config\": config,\n",
    "    \"test_accuracies\": test_accuracies\n",
    "}\n",
    "\n",
    "with open(artifact_filename + \".json\", \"w\") as f:\n",
    "    f.write(json.dumps(data, indent=4))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "aml-batched.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "057192c358aa4fd2bbcd7c0e142ac83f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e9d347b655f4baa92b905b57afa346a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_61601de27b6641f4a32af8e8afe1925d",
       "IPY_MODEL_46263493fc1e462fb2dc5758a5f4520d",
       "IPY_MODEL_64b39222fa26456d940f4d5aa2091d10"
      ],
      "layout": "IPY_MODEL_4a0e26f46b6b4765a9c64f39af19584a"
     }
    },
    "1eee39395eac4ad1869e3eb59b9b0280": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25d6469997614e298a5c982b65258355": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8086c7228bf44b62b0a454d70e912ef6",
       "IPY_MODEL_2d6524f654134b0f90197d71e2e29112",
       "IPY_MODEL_bb884a5f31ff4c7394cdb564abbb60ce"
      ],
      "layout": "IPY_MODEL_58331fdef2d1484286d3743c93801951"
     }
    },
    "2d6524f654134b0f90197d71e2e29112": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8d41ac06d9e480d994e4a291e426fef",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f24d6aa9bdae4e7b8e49af8031164967",
      "value": 379
     }
    },
    "343ff4eb9a7647a19bf2a5b7b0d74a90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34f1328f26434b01b228e4ab524a7b71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40d44046a060465b8c462dd38b1ab90f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "46263493fc1e462fb2dc5758a5f4520d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_057192c358aa4fd2bbcd7c0e142ac83f",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5258ca5e78c643dfbb2467ae01d3e5d5",
      "value": 170498071
     }
    },
    "4a0e26f46b6b4765a9c64f39af19584a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5258ca5e78c643dfbb2467ae01d3e5d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "58331fdef2d1484286d3743c93801951": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61601de27b6641f4a32af8e8afe1925d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9743ce9bf2b9495daf94a45b5a1892c7",
      "placeholder": "​",
      "style": "IPY_MODEL_40d44046a060465b8c462dd38b1ab90f",
      "value": ""
     }
    },
    "64b39222fa26456d940f4d5aa2091d10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_343ff4eb9a7647a19bf2a5b7b0d74a90",
      "placeholder": "​",
      "style": "IPY_MODEL_de271fef704c4f89b4549efed5daf3b6",
      "value": " 170499072/? [00:07&lt;00:00, 24188856.90it/s]"
     }
    },
    "8086c7228bf44b62b0a454d70e912ef6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34f1328f26434b01b228e4ab524a7b71",
      "placeholder": "​",
      "style": "IPY_MODEL_f25c081635eb4d05b90fd96539504e80",
      "value": " 38%"
     }
    },
    "9743ce9bf2b9495daf94a45b5a1892c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8d41ac06d9e480d994e4a291e426fef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb884a5f31ff4c7394cdb564abbb60ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1eee39395eac4ad1869e3eb59b9b0280",
      "placeholder": "​",
      "style": "IPY_MODEL_f48bef0609b9476eaa19ca03a6ebb4f4",
      "value": " 379/1000 [06:03&lt;09:54,  1.04it/s]"
     }
    },
    "de271fef704c4f89b4549efed5daf3b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f24d6aa9bdae4e7b8e49af8031164967": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f25c081635eb4d05b90fd96539504e80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f48bef0609b9476eaa19ca03a6ebb4f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
