{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattiadutto/aml_federeted_learning/blob/dev_grouped_convolutions/aml_batched.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRyFWIxiPEVX"
      },
      "source": [
        "# Baseline implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN9_GO3YcGI9",
        "outputId": "3d5594e0-9694-4af3-9fc2-ddb508a9cb00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.7 MB 12.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 47.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 51.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install wandb --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7iCHpO-d0SR",
        "outputId": "186179ce-3045-4743-ac31-ceae787c248e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-03 17:19:00--  http://storage.googleapis.com/gresearch/federated-vision-datasets/cifar10.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.133.128, 74.125.140.128, 108.177.15.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.133.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1627997 (1.6M) [application/zip]\n",
            "Saving to: ‘cifar10.zip’\n",
            "\n",
            "\rcifar10.zip           0%[                    ]       0  --.-KB/s               \rcifar10.zip         100%[===================>]   1.55M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-01-03 17:19:00 (155 MB/s) - ‘cifar10.zip’ saved [1627997/1627997]\n",
            "\n",
            "Archive:  cifar10.zip\n",
            "   creating: cifar10/\n",
            "  inflating: cifar10/federated_train_alpha_0.00.csv  \n",
            "  inflating: cifar10/test.csv        \n",
            "  inflating: cifar10/federated_train_alpha_10.00.csv  \n",
            "  inflating: cifar10/federated_train_alpha_0.05.csv  \n",
            "  inflating: cifar10/federated_train_alpha_100.00.csv  \n",
            "  inflating: cifar10/federated_train_alpha_0.10.csv  \n",
            "  inflating: cifar10/federated_train_alpha_0.20.csv  \n",
            "  inflating: cifar10/federated_train_alpha_1.00.csv  \n",
            "  inflating: cifar10/federated_train_alpha_0.50.csv  \n"
          ]
        }
      ],
      "source": [
        "!wget http://storage.googleapis.com/gresearch/federated-vision-datasets/cifar10.zip\n",
        "!unzip cifar10.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "X82NHRCAcXLl",
        "outputId": "206d9ed2-59c9-44a1-9ecc-c43b94ae050f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init(project=\"step-2\", entity=\"aml-federated-learning\", mode=\"disabled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ww5uiZ6HfmBd"
      },
      "outputs": [],
      "source": [
        "E = 1\n",
        "STEP_SIZE = 5\n",
        "GAMMA = 0.1\n",
        "\n",
        "# K = 1, NUMBE_OR_CLIENTS = 2, MAX_TIME = 3 -> 58 sec\n",
        "\n",
        "K = 10 # to set\n",
        "NUMBER_OF_CLIENTS = 100 # to set\n",
        "MAX_TIME = 1000 #to set\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "lr = 0.05\n",
        "\n",
        "DATA_DISTRIBUTION = \"non-iid\" # \"iid\" | \"non-iid\"\n",
        "DIRICHELET_ALPHA = 0.05 # 0.00, 0.05, 0.10, 0.20, 0.50, 1.00, 10.00, 100.0\n",
        "\n",
        "assert(DATA_DISTRIBUTION == \"iid\" or NUMBER_OF_CLIENTS == 100)\n",
        "\n",
        "\n",
        "wandb.config.update({\n",
        "    \"batch-size\": batch_size,\n",
        "    \"learning-rate\": lr,\n",
        "    # \"momentum\": MOMENTUM,\n",
        "    # \"weight_decay\": WEIGHT_DECAY,\n",
        "    \"num_epochs\": E,\n",
        "    \"step_size\": STEP_SIZE,\n",
        "    \"gamma\": GAMMA,\n",
        "    \"K\": K,\n",
        "    \"number_of_clients\": NUMBER_OF_CLIENTS,\n",
        "    \"max_time\": MAX_TIME,\n",
        "    \"data_distribution\": DATA_DISTRIBUTION,\n",
        "    \"dirichelet_alpha\": DIRICHELET_ALPHA\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5Ar1b6p68b3G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# From: https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square, you can specify with a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "seEKXjiixeCq"
      },
      "outputs": [],
      "source": [
        "# From: https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
        "class BatchedNet(nn.Module):\n",
        "\n",
        "    def __init__(self, parallelism):\n",
        "        super(BatchedNet, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
        "        self.P = parallelism\n",
        "        self.ops = nn.Sequential(\n",
        "            nn.Conv2d(3 * self.P, 6 * self.P, 5, groups=self.P),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2)),\n",
        "            nn.Conv2d(6 * self.P, 16 * self.P, 5, groups=self.P),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            #nn.Flatten(1, -1)\n",
        "        )\n",
        "        self.ops2 = nn.Sequential(\n",
        "            nn.Conv1d(16 * 5 * 5 * self.P, 120 * self.P,\n",
        "                      kernel_size=1, groups=self.P),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(120 * self.P, 84 * self.P, kernel_size=1, groups=self.P),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(84 * self.P, 10 * self.P, kernel_size=1, groups=self.P)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ops(x)\n",
        "        x = x.view(batch_size, -1, 1)\n",
        "        return self.ops2(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eCwGFjE5Feil"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "class Client():\n",
        "  def __init__(self, i, train_set, validation_set):\n",
        "    self.i = i\n",
        "    self.train_set = train_set\n",
        "    self.batch_size = 32\n",
        "    self.train_loader = torch.utils.data.DataLoader(train_set, batch_size=len(train_set),\n",
        "                                         shuffle=False, num_workers=0, pin_memory=True)\n",
        "    #self.validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size,\n",
        "    #                                     shuffle=False, num_workers=0)\n",
        "    #self.net = Net()\n",
        "    #self.net = self.net.to(device)\n",
        "    # create your optimizer\n",
        "    #self.optimizer = optim.SGD(self.net.parameters(), lr=lr)\n",
        "    #self.criterion = nn.CrossEntropyLoss()\n",
        "    # self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "    #wandb.watch(self.net, criterion=self.criterion, log_freq=100, log_graph=True)\n",
        "    \n",
        "  \"\"\"def clientUpdate(self, parameters):\n",
        "    self.net.load_state_dict(parameters)\n",
        "    theta = parameters\n",
        "    for e in range(E):\n",
        "      for images, labels in self.train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # in your training loop:\n",
        "        self.optimizer.zero_grad()   # zero the gradient buffers\n",
        "        output = self.net(images)\n",
        "        loss = self.criterion(output, labels)\n",
        "        loss.backward()\n",
        "        wandb.log({f\"client-loss-{self.i}\": loss.item()})\n",
        "        self.optimizer.step()    # Does the update\n",
        "    \n",
        "    return_dict = {}\n",
        "    for (k1, v1), (k2, v2) in zip(parameters.items(), self.net.state_dict().items()):\n",
        "      return_dict[k1] = v1 - v2\n",
        "    return return_dict\n",
        "\n",
        "  def compute_accuracy(self, parameters):\n",
        "    self.net.load_state_dict(parameters)\n",
        "\n",
        "    running_corrects = 0\n",
        "    n = 0\n",
        "    for data, labels in self.validation_loader:\n",
        "        data = data.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = self.net(data)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        n += len(preds)\n",
        "                \n",
        "    return running_corrects / n\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QcsNecZCVPP-"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def parse_csv(filename):\n",
        "  splits = defaultdict(lambda: [])\n",
        "  with open(filename) as f:\n",
        "    for line in f:\n",
        "      if not line[0].isdigit():\n",
        "        continue\n",
        "\n",
        "      user_id, image_id, _ = (int(token) for token in line.split(\",\"))\n",
        "      splits[user_id].append(image_id)\n",
        "\n",
        "  return splits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515,
          "referenced_widgets": [
            "1e9d347b655f4baa92b905b57afa346a",
            "4a0e26f46b6b4765a9c64f39af19584a",
            "61601de27b6641f4a32af8e8afe1925d",
            "46263493fc1e462fb2dc5758a5f4520d",
            "64b39222fa26456d940f4d5aa2091d10",
            "40d44046a060465b8c462dd38b1ab90f",
            "9743ce9bf2b9495daf94a45b5a1892c7",
            "5258ca5e78c643dfbb2467ae01d3e5d5",
            "057192c358aa4fd2bbcd7c0e142ac83f",
            "de271fef704c4f89b4549efed5daf3b6",
            "343ff4eb9a7647a19bf2a5b7b0d74a90",
            "25d6469997614e298a5c982b65258355",
            "58331fdef2d1484286d3743c93801951",
            "8086c7228bf44b62b0a454d70e912ef6",
            "2d6524f654134b0f90197d71e2e29112",
            "bb884a5f31ff4c7394cdb564abbb60ce",
            "f25c081635eb4d05b90fd96539504e80",
            "34f1328f26434b01b228e4ab524a7b71",
            "f24d6aa9bdae4e7b8e49af8031164967",
            "a8d41ac06d9e480d994e4a291e426fef",
            "f48bef0609b9476eaa19ca03a6ebb4f4",
            "1eee39395eac4ad1869e3eb59b9b0280"
          ]
        },
        "id": "gTmw78eJ-EW5",
        "outputId": "4df9612c-dc7f-4cbc-bba7-de7725e71694"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e9d347b655f4baa92b905b57afa346a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "10000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25d6469997614e298a5c982b65258355",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-395a39a22c27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;31m# apply the gradient descent step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import random\n",
        "from time import perf_counter_ns\n",
        "\n",
        "from tqdm.notebook import tqdm, trange\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "\n",
        "if DATA_DISTRIBUTION == \"iid\":\n",
        "    # split the training set\n",
        "    trainset_len = (len(trainset) // NUMBER_OF_CLIENTS) * NUMBER_OF_CLIENTS\n",
        "    print(trainset_len)\n",
        "    trainset = torch.utils.data.Subset(trainset, list(range(trainset_len)))\n",
        "\n",
        "    lengths = len(trainset) // NUMBER_OF_CLIENTS * \\\n",
        "        np.ones(NUMBER_OF_CLIENTS, dtype=int)\n",
        "    print(lengths)\n",
        "    trainsets = torch.utils.data.random_split(\n",
        "        dataset=trainset, lengths=lengths)\n",
        "else:\n",
        "    dirichelet_splits = parse_csv(\n",
        "        f\"cifar10/federated_train_alpha_{DIRICHELET_ALPHA:.2f}.csv\")\n",
        "    trainsets = [torch.utils.data.Subset(\n",
        "        trainset, indices) for indices in dirichelet_splits.values()]\n",
        "\n",
        "\n",
        "# split the validation set\n",
        "testset_len = (len(testset) // NUMBER_OF_CLIENTS) * NUMBER_OF_CLIENTS\n",
        "print(testset_len)\n",
        "testset = torch.utils.data.Subset(testset, list(range(testset_len)))\n",
        "\n",
        "lengths = len(testset) // NUMBER_OF_CLIENTS * \\\n",
        "    np.ones(NUMBER_OF_CLIENTS, dtype=int)\n",
        "# print(lengths)\n",
        "testsets = torch.utils.data.random_split(dataset=testset, lengths=lengths)\n",
        "\n",
        "\n",
        "clientsSizes = torch.zeros(NUMBER_OF_CLIENTS)\n",
        "clients = list()\n",
        "\n",
        "# server reference model\n",
        "reference = BatchedNet(1).to(device)\n",
        "\n",
        "\n",
        "def selectClients(k):\n",
        "    return random.sample(clients, k=k)\n",
        "\n",
        "\n",
        "def aggregateClient(deltaThetas):\n",
        "    parameters = None\n",
        "    for i, d in enumerate(deltaThetas):\n",
        "        ratio = len(trainsets[i])/len(trainset)\n",
        "\n",
        "        if i == 0:\n",
        "            parameters = {k: ratio*v for k, v in d.items()}\n",
        "        else:\n",
        "            for (k, v) in d.items():\n",
        "                parameters[k] += ratio * v\n",
        "\n",
        "    return parameters\n",
        "\n",
        "\n",
        "for c in range(NUMBER_OF_CLIENTS):\n",
        "    clients.append(Client(c, trainsets[c], testsets[c]))\n",
        "\n",
        "\n",
        "batched_model = BatchedNet(K).to(device)\n",
        "batched_optimizer = optim.SGD(batched_model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "\n",
        "# move all the images and labels used by the selected clients to the gpu\n",
        "# in one single pass\n",
        "client_images, client_labels = [], []\n",
        "for client in clients:\n",
        "    # take all the images and labels used by the selected client\n",
        "    images, labels = next(iter(client.train_loader))\n",
        "    client_images.append(images.to(device))\n",
        "    client_labels.append(labels.view((-1, 1)).to(device))\n",
        "\n",
        "\n",
        "for step in trange(MAX_TIME):\n",
        "    selected_clients = selectClients(K)\n",
        "    selected_ids = [c.i for c in selected_clients]\n",
        "\n",
        "    #t_2 = perf_counter_ns()\n",
        "\n",
        "    # move all the images and labels used by the selected clients to the gpu\n",
        "    # in one single pass\n",
        "    # client_images, client_labels = [], []\n",
        "    # for selected_client in selected_clients:\n",
        "    #     # take all the images and labels used by the selected client\n",
        "    #     images, labels = next(iter(selected_client.train_loader))\n",
        "    #     client_images.append(images.to(device))\n",
        "    #     client_labels.append(labels.view((-1, 1)).to(device))\n",
        "\n",
        "    selected_client_images = [ci for i, ci in enumerate(client_images) if i in selected_ids]\n",
        "    selected_client_labels = [cl for i, cl in enumerate(client_labels) if i in selected_ids]\n",
        "\n",
        "    # client_images[i] is a Tensor of shape [Ni, 3, 32, 32] where Ni is the number of images\n",
        "    # assigned to client i\n",
        "\n",
        "    #t_1 = perf_counter_ns()\n",
        "\n",
        "    # load the batched model state dict by stacking K times the parameters of the server model (reference)\n",
        "    parameters = {key: torch.stack([params] * K).flatten(0, 1)\n",
        "                  for key, params in reference.state_dict().items()}\n",
        "    batched_model.load_state_dict(parameters)\n",
        "\n",
        "    #t0 = perf_counter_ns()\n",
        "    for epoch in range(E):\n",
        "        # for each local epoch\n",
        "\n",
        "        n_batches = selected_client_images[0].shape[0] // batch_size\n",
        "\n",
        "        for i in range(n_batches):\n",
        "            # for each local batch\n",
        "\n",
        "            batched_optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            # load all the batches (one batch for each client)\n",
        "            batch_images = [ci[i*batch_size:(i+1)*batch_size] for ci in selected_client_images]\n",
        "            batch_labels = [cl[i*batch_size:(i+1)*batch_size] for cl in selected_client_labels]\n",
        "\n",
        "            # reshape the batches as one tensor of shape [batch_size, K * 3, 32, 32]\n",
        "            batch_images = torch.stack(batch_images).view((batch_size, -1, 32, 32))\n",
        "            # print(batch_images.shape)\n",
        "\n",
        "            # compute the batch ouput of the model\n",
        "            # output[:, 10*i:10*(i+1)] is the model output for client i\n",
        "            # shape of output is [10, 100, 1]\n",
        "            output = batched_model(batch_images) \n",
        "\n",
        "            # compute the loss separately for each client\n",
        "            loss = 0\n",
        "            for _output, _labels in zip(torch.chunk(output, batch_size, dim=1), batch_labels):\n",
        "               loss += criterion(_output, _labels)\n",
        "            loss.backward()\n",
        "\n",
        "            # apply the gradient descent step\n",
        "            batched_optimizer.step()\n",
        "    \n",
        "    #t1 = perf_counter_ns()\n",
        "\n",
        "    # extract the parameters of each client\n",
        "    client_params = [dict() for _ in range(K)]\n",
        "    for key, batched_parameters in batched_model.state_dict().items():\n",
        "        # for each entry of the state dict\n",
        "\n",
        "        # s represents the number of parameters of client i\n",
        "        s = batched_parameters.shape[0] // K\n",
        "        for i in range(K):\n",
        "            # extract the parameters of client i\n",
        "            client_params[i][key] = parameters[key][i * s: (i+1)*s] - batched_parameters[i * s: (i+1)*s]\n",
        "\n",
        "    #t2 = perf_counter_ns()\n",
        "    g = aggregateClient(client_params)\n",
        "    #t3 = perf_counter_ns()\n",
        "\n",
        "    parameters = dict()\n",
        "    for (k1, v1), v2 in zip(reference.state_dict().items(), g.values()):\n",
        "      parameters[k1] = v1 - v2 # todo: add server learning rate gamma\n",
        "\n",
        "    #t4 = perf_counter_ns()\n",
        "    reference.load_state_dict(parameters)\n",
        "\n",
        "    # print(\"Data loading:\", t_1-t_2)\n",
        "    # print(\"Model setup time:\", t0-t_1)\n",
        "    # print(\"Training time:\", t1-t0)\n",
        "    # print(\"Clients parameters extraction:\", t2-t1)\n",
        "    # print(\"Aggregation:\", t3-t2)\n",
        "    # print(\"Computation of new parameters:\", t4-t3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lj2oqawRbnF-"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "print(Counter(label for _, label in iter(trainsets[0])))\n",
        "print(Counter(label for _, label in iter(trainsets[1])))\n",
        "print(Counter(label for _, label in iter(trainsets[2])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utb7E9snmQwi"
      },
      "outputs": [],
      "source": [
        "from statistics import mean\n",
        "\n",
        "model_parameters = net.state_dict()\n",
        "avg_accuracy = mean(client.compute_accuracy(model_parameters) for client in clients)\n",
        "\n",
        "print(f\"Average accuracy after {MAX_TIME} rounds is {avg_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yo5tYPNmxQz"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "timestr = time.strftime(\"%Y_%m_%d-%I_%M_%S_%p\")\n",
        "artifact_filename = f\"artifacts/server_model-{timestr}.pth\"\n",
        "\n",
        "# parameters of the trained model\n",
        "server_model = net.state_dict()\n",
        "# save the model on the local file system\n",
        "torch.save(server_model, artifact_filename)\n",
        "# save the model on wandb\n",
        "wandb.save(artifact_filename)\n",
        "\n",
        "# Finish the wandb session and upload all data\n",
        "wandb.finish(0, quiet=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "aml-batched.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e9d347b655f4baa92b905b57afa346a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4a0e26f46b6b4765a9c64f39af19584a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_61601de27b6641f4a32af8e8afe1925d",
              "IPY_MODEL_46263493fc1e462fb2dc5758a5f4520d",
              "IPY_MODEL_64b39222fa26456d940f4d5aa2091d10"
            ]
          }
        },
        "4a0e26f46b6b4765a9c64f39af19584a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61601de27b6641f4a32af8e8afe1925d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_40d44046a060465b8c462dd38b1ab90f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9743ce9bf2b9495daf94a45b5a1892c7"
          }
        },
        "46263493fc1e462fb2dc5758a5f4520d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5258ca5e78c643dfbb2467ae01d3e5d5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_057192c358aa4fd2bbcd7c0e142ac83f"
          }
        },
        "64b39222fa26456d940f4d5aa2091d10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_de271fef704c4f89b4549efed5daf3b6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:07&lt;00:00, 24188856.90it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_343ff4eb9a7647a19bf2a5b7b0d74a90"
          }
        },
        "40d44046a060465b8c462dd38b1ab90f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9743ce9bf2b9495daf94a45b5a1892c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5258ca5e78c643dfbb2467ae01d3e5d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "057192c358aa4fd2bbcd7c0e142ac83f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de271fef704c4f89b4549efed5daf3b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "343ff4eb9a7647a19bf2a5b7b0d74a90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25d6469997614e298a5c982b65258355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_58331fdef2d1484286d3743c93801951",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8086c7228bf44b62b0a454d70e912ef6",
              "IPY_MODEL_2d6524f654134b0f90197d71e2e29112",
              "IPY_MODEL_bb884a5f31ff4c7394cdb564abbb60ce"
            ]
          }
        },
        "58331fdef2d1484286d3743c93801951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8086c7228bf44b62b0a454d70e912ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f25c081635eb4d05b90fd96539504e80",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 38%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_34f1328f26434b01b228e4ab524a7b71"
          }
        },
        "2d6524f654134b0f90197d71e2e29112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f24d6aa9bdae4e7b8e49af8031164967",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 379,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8d41ac06d9e480d994e4a291e426fef"
          }
        },
        "bb884a5f31ff4c7394cdb564abbb60ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f48bef0609b9476eaa19ca03a6ebb4f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 379/1000 [06:03&lt;09:54,  1.04it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1eee39395eac4ad1869e3eb59b9b0280"
          }
        },
        "f25c081635eb4d05b90fd96539504e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "34f1328f26434b01b228e4ab524a7b71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f24d6aa9bdae4e7b8e49af8031164967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8d41ac06d9e480d994e4a291e426fef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f48bef0609b9476eaa19ca03a6ebb4f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1eee39395eac4ad1869e3eb59b9b0280": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}