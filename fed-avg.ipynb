{"cells":[{"cell_type":"markdown","metadata":{"id":"KRyFWIxiPEVX"},"source":["# Federated Learning based on Federated Averaging"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from os import path\n","import urllib.request\n","import zipfile\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","from collections import defaultdict\n","\n","import json\n","from copy import deepcopy\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","import random\n","from statistics import mean\n","\n","from tqdm.notebook import tqdm\n","\n","import os\n","random.seed(42)"]},{"cell_type":"markdown","metadata":{},"source":["## Configuration"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["config = {\n","    \"E\": 1, # number of local epochs\n","    \"K\": 5, # number of clients selected each round # [5, 10, 20]\n","    \"NUMBER_OF_CLIENTS\": 100, # total number of clients\n","    \"MAX_TIME\": 5000, # number of rounds\n","    \"BATCH_SIZE\": 50,\n","    \"VALIDATION_BATCH_SIZE\": 500,\n","    \"LR\": 0.01, # learning rate\n","    \"WEIGHT_DECAY\": 4e-4,\n","    \"DATA_DISTRIBUTION\": \"non-iid\", # \"iid\" | \"non-iid\"\n","    \"DIRICHELET_ALPHA\": [0.00, 0.05, 0.10, 0.20, 0.50, 1.00, 10.00, 100.0],\n","    \"AVERAGE_ACCURACY\": np.zeros(8),\n","    \"FED_AVG_M\": False,\n","    \"FED_AVG_M_BETA\": 0.9,\n","    \"FED_AVG_M_GAMMA\": 1,\n","    \"LR_DECAY\": 0.99,\n","    \"LOG_FREQUENCY\": 25, # frequency of logs printed\n","    \"AUGMENTATION_PROB\": 0.0, # for data transformation, see below (Prepare dataset cells)\n","    \"SAVE_FREQUENCY\": 100, # frequency of logs saved\n","    \"NORM_LAYER\": \"\", # Normalization layer [None: \"\", Batch: \"bn\", Group: \"gn\"]\n","}\n","\n","use_data_preloading = True"]},{"cell_type":"markdown","metadata":{},"source":["## CIFAR-10"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# download the Cifar10 non-iid splits, if not present\n","if not path.exists(\"cifar10\"):\n","    save_path = \"cifar10.zip\"\n","    urllib.request.urlretrieve(\"http://storage.googleapis.com/gresearch/federated-vision-datasets/cifar10_v1.1.zip\", save_path)\n","    \n","    with zipfile.ZipFile(save_path, 'r') as zip_ref:\n","        zip_ref.extractall(\"cifar10\")\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"markdown","metadata":{},"source":["## Prepare dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Random transformations to provide data augmentation\n","random_transform = transforms.Compose(\n","    [\n","        transforms.RandomCrop(32, padding=4),\n","        transforms.RandomHorizontalFlip(1),\n","        transforms.ColorJitter(0.9, 0.9)\n","    ]\n",")\n","# Normalization values for the CIFAR10 dataset\n","normalization_transform = transforms.Normalize(\n","    mean=[0.491, 0.482, 0.447], \n","    std=[0.247, 0.243, 0.262]\n",")\n","\n","# Transformation strategy:\n","#  1. apply as many transformations as possibile offline (at trainset level)\n","#  2. apply the remaining transformations online (at client level, before\n","#     iterating over the data)\n","#  \n","# Random transformations must be applied online.\n","\n","if use_data_preloading:\n","    # Data preloading is enabled\n","    \n","    if config[\"AUGMENTATION_PROB\"] > 1e-5:\n","        # Non-zero augmentation probability => apply transformations online\n","        offline_train_transform = None\n","        online_train_transform = transforms.Compose([\n","            transforms.RandomApply([random_transform], config[\"AUGMENTATION_PROB\"]),\n","            normalization_transform\n","        ])\n","    else:\n","        # Zero augmentation probability => apply transformations offline\n","        offline_train_transform = normalization_transform\n","        online_train_transform = None\n","else:\n","    # Augmentation probability is zero => all transformations can be applied offline\n","    offline_train_transform = transforms.Compose([\n","        transforms.RandomApply([random_transform], config[\"AUGMENTATION_PROB\"]),\n","        normalization_transform\n","    ])\n","    online_train_transform = None\n","    \n","\n","trainset = torchvision.datasets.CIFAR10(\n","    root='./data', \n","    train=True,\n","    download=True, \n","    transform=transforms.Compose([transforms.ToTensor(), offline_train_transform])\n",")\n","\n","testset = torchvision.datasets.CIFAR10(\n","    root='./data', \n","    train=False,\n","    download=True, \n","    transform=transforms.Compose([transforms.ToTensor(), normalization_transform])\n","  )"]},{"cell_type":"markdown","metadata":{},"source":["## LeNet-5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Ar1b6p68b3G","outputId":"e695f455-87f7-44c6-fe6f-fb6bdf6b300d","trusted":true},"outputs":[],"source":["# From: https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        \n","        self.conv1 = nn.Conv2d(3, 64, 5)\n","        if config[\"NORM_LAYER\"] == \"bn\": # if batch normalization\n","            self.norm1 = nn.BatchNorm2d(64)\n","        elif config[\"NORM_LAYER\"] == \"gn\": # if group normalization\n","            self.norm1 = nn.GroupNorm(4, 64)\n","        \n","        self.conv2 = nn.Conv2d(64, 64, 5)\n","        if config[\"NORM_LAYER\"] == \"bn\":\n","            self.norm2 = nn.BatchNorm2d(64)\n","        elif config[\"NORM_LAYER\"] == \"gn\":\n","            self.norm2 = nn.GroupNorm(4, 64)\n","        \n","        self.fc1 = nn.Linear(64 * 5 * 5, 384)\n","        self.fc2 = nn.Linear(384, 192)\n","        self.fc3 = nn.Linear(192, 10)\n","\n","    def forward(self, x):\n","        if config[\"NORM_LAYER\"] in ['bn', 'gn']:\n","            x = F.max_pool2d(F.relu(self.norm1(self.conv1(x))), (2,2))\n","            x = F.max_pool2d(F.relu(self.norm2(self.conv2(x))), 2)\n","        else:\n","            x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n","            x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n","        \n","        x = torch.flatten(x, 1) \n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["## Client"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eCwGFjE5Feil","trusted":true},"outputs":[],"source":["class Client:\n","    def __init__(self, i, train_set, validation_set, *, input_size=32, use_data_preloading, train_transform):\n","        \"\"\"Instantiate a new client\n","\n","        The parameter `use_data_preloading` allows to indicate whether the client should\n","        preload all its training and validation data before starting the training loop. This\n","        is preferred since it drastically speeds up the training proccess. Beware that, depending\n","        on the dataset, the memory usage may quickly becoming unfeasible. 100 clients, each\n","        with its own data and network, requires ~2.5 GB of gpu memory.\n","        `train_transform` is a pytorch transform to be applied on each sample at training time.\n","        \"\"\"\n","        self.i = i\n","        self.net = Net()\n","        self.net = self.net.to(device)\n","        \n","        # Create the dataloader for the validation data\n","        self.validation_loader = torch.utils.data.DataLoader(validation_set,\n","            batch_size=len(validation_set),\n","            shuffle=False, num_workers=0\n","        )\n","        \n","        # Create an optimizer for the model's parameters\n","        self.optimizer = optim.SGD(self.net.parameters(), lr=config[\"LR\"], weight_decay=config[\"WEIGHT_DECAY\"])\n","        # Create the loss criterion\n","        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n","        \n","        self.train_transform = train_transform\n","\n","        self.use_data_preloading = use_data_preloading\n","        if self.use_data_preloading:\n","            # Preloading train (the batch size config is ignored here)\n","            self.train_loader = torch.utils.data.DataLoader(train_set,\n","                batch_size=len(train_set), shuffle=True, \n","                num_workers=0, pin_memory=True\n","            )\n","            \n","            # Read all the dataset at once...\n","            training_images, training_labels = next(iter(self.train_loader))\n","            # ...and transfer the data on the target device\n","            self.training_images = training_images.to(device)\n","            self.training_labels = training_labels.to(device)\n","            \n","            # Preload the validation images\n","            validation_images, validation_labels = next(iter(self.validation_loader))\n","             # ...and transfer the data on the target device\n","            self.validation_images = validation_images.to(device)\n","            self.validation_labels = validation_labels.to(device)\n","        else:\n","            # Preloading was not requested => a dataloader is initialized as usual\n","            self.train_loader = torch.utils.data.DataLoader(train_set, \n","                batch_size=config[\"BATCH_SIZE\"], shuffle=True, \n","                num_workers=0, pin_memory=True\n","            )\n","\n","    def clientUpdate(self, parameters):\n","        \"\"\"Run a step of client training\n","\n","        Parameters\n","        ----------\n","        parameters : OrderedDict[str, torch.Tensor]\n","            Initial parameters of the client model\n","\n","        Returns\n","        -------\n","            epoch loss,\n","        OrderedDict[str, torch.Tensor]\n","            new parameters of the client at the end of the training step\n","        \"\"\"\n","        # Restore the parameters of the network from the server model\n","        self.net.load_state_dict(parameters)\n","        self.net.train()\n","\n","        for _ in range(config[\"E\"]):\n","            # Compute the total epoch loss\n","            epoch_loss, n = 0, 0\n","            for images, labels in self.iter_training_data():\n","                # Set gradients to zero\n","                self.optimizer.zero_grad()  \n","                outputs = self.net(images)\n","\n","                # Compute the loss of the model\n","                loss = self.criterion(outputs, labels)\n","                epoch_loss += loss\n","\n","                n += labels.size(0)\n","                loss = loss / labels.size(0)\n","                # Backward step\n","                loss.backward()\n","                self.optimizer.step()  \n","\n","            epoch_loss = epoch_loss / n\n","        \n","        # Computing the returning dict\n","        return_dict = {}\n","        for (k1, v1), (_, v2) in zip(parameters.items(), self.net.state_dict().items()):\n","            return_dict[k1] = v1 - v2\n","        return epoch_loss, return_dict\n","\n","    def iter_training_data(self):\n","        \"\"\"Iterate over the training data of the client\n","\n","        Yields\n","        -------\n","        Generator[torch.Tensor]\n","            the training dataset, split in mini-batches\n","        \"\"\"\n","        batch_size = config[\"BATCH_SIZE\"]\n","\n","        if self.use_data_preloading:\n","            # Data already preloaded => shuffle and return from cache\n","            indices = torch.randperm(self.training_images.size(0))\n","            training_images, training_labels = self.training_images[indices], self.training_labels[indices]\n","            \n","            # Possibly apply the required training transformation\n","            if self.train_transform is not None:\n","                training_images = torch.stack([self.train_transform(im) for im in training_images])\n","            \n","            # Yield the training set\n","            yield from zip(torch.split(training_images, batch_size), torch.split(training_labels, batch_size))\n","        else:\n","            # Data not already preloaded => yield from the dataloader\n","            for images, labels in self.train_loader:\n","                images = images.to(device)\n","                labels = labels.to(device)\n","                yield images, labels\n","                \n","    def iter_validation_data(self):\n","        \"\"\"Iterate over the validation data of the the client\n","\n","        Yields\n","        -------\n","        Generator[torch.Tensor]\n","            the validation dataset, split in mini-batches\n","        \"\"\"\n","        batch_size = config[\"VALIDATION_BATCH_SIZE\"]\n","\n","        if self.use_data_preloading:\n","            # Data already preloaded => return from cache\n","            yield from zip(torch.split(self.validation_images, batch_size), torch.split(self.validation_labels, batch_size))\n","        else:\n","            # Data not already preloaded => yield from the dataloader\n","            for images, labels in self.validation_loader:\n","                images = images.to(device)\n","                labels = labels.to(device)\n","                yield images, labels\n","           \n","    def compute_accuracy(self, parameters):\n","        \"\"\"Compute the accuracy of the client\n","\n","        Parameters\n","        ----------\n","        parameters : OrderedDict[str, torch.Tensor]\n","            parameters of the client\n","\n","        Returns\n","        -------\n","        Tuple[float, float]\n","            average loss on the validation set, accuracy on the validation set\n","        \"\"\"\n","        self.net.load_state_dict(parameters)\n","        # Set the model in evaluation mode\n","        self.net.eval()\n","\n","        running_corrects = 0\n","        loss, n = 0, 0\n","        for data, labels in self.iter_validation_data():\n","            with torch.no_grad():\n","                # Compute the network outputs without gradients\n","                outputs = self.net(data)\n","            # Compute the validation \n","            loss += self.criterion(outputs, labels).item()\n","\n","            # Count the number of correct predictions\n","            _, preds = torch.max(outputs.data, 1)\n","\n","            running_corrects += torch.sum(preds == labels.data).data.item()\n","            n += len(preds)\n","\n","        return loss / n, running_corrects / n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QcsNecZCVPP-","trusted":true},"outputs":[],"source":["def parse_csv(filename):\n","    \"\"\"Read a CIFAR-10 splits file\n","\n","    Parameters\n","    ----------\n","    filename : str\n","        path of the .csv file containing the splits\n","\n","    Returns\n","    -------\n","    Tuple[DefaultDict[int, List[int]], Dict[int, int]]\n","        the dictionary containing the splits as user_id:[image_id]\n","        and the labels_mapping as image_id:label\n","    \"\"\"\n","    splits = defaultdict(lambda: [])\n","    labels_mapping = dict()\n","\n","    with open(filename) as f:\n","        for line in f:\n","            if not line[0].isdigit():\n","                # Skip the first line\n","                continue\n","\n","            user_id, image_id, label = (int(token) for token in line.split(\",\"))\n","            splits[user_id].append(image_id)\n","            labels_mapping[image_id] = label\n","\n","    return splits, labels_mapping"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def printJSON(alpha, acc, net, step = None):\n","    \"\"\"Create the json artifacts file\n","\n","    Parameters\n","    ----------\n","    alpha: float\n","        value of alpha\n","    acc: list\n","        list of accuracies at different iterations\n","    net: the actual network configuration\n","    step: int\n","        current value of iteration\n","    \"\"\"\n","    artifacts_dir = \"artifacts\"\n","\n","    artifact_filename = f\"ALPHA_{alpha}_E_{config['E']}_K_{config['K']}\"\n","    if step is not None:\n","      artifact_filename += f\"_STEPS_{step}\"\n","    \n","    if config[\"AUGMENTATION_PROB\"] > 0:\n","      artifact_filename += f\"_T\"\n","\n","    artifact_filename += f\"_{config['NORM_LAYER'].upper()}\" if config['NORM_LAYER'] else \"\"\n","      \n","    # Parameters of the trained model\n","    server_model = net.state_dict()\n","    # Save the model on the local file system\n","    torch.save(server_model, f\"{artifacts_dir}/{artifact_filename}.pth\")\n","    config_copy = deepcopy(config)\n","\n","    # remove DIRICHELET_ALPHA and AVERAGE_ACCURACY (no need to log them)\n","    del config_copy[\"DIRICHELET_ALPHA\"]\n","    del config_copy[\"AVERAGE_ACCURACY\"]\n","    data = {\n","        \"config\": config_copy,\n","        \"alpha\": alpha,\n","        \"accuracy\": acc\n","    }\n","\n","    with open(f\"{artifacts_dir}/{artifact_filename}.json\", \"w\") as f:\n","        f.write(json.dumps(data, indent=4))"]},{"cell_type":"markdown","metadata":{},"source":["## Client selection and aggregation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def selectClients(k):\n","  \"\"\"\n","  It select k random clients\n","\n","  Parameters\n","  ----------\n","  k : int\n","    number of client to sample\n","\n","  Returns\n","  -------\n","  It return the list of selected clients.\n","  \"\"\"\n","  return random.sample(clients, k=k)\n","\n","def aggregateClient(deltaThetas):\n","  \"\"\"\n","  Compute the aggregation of parameters of different clients\n","  Parameters\n","  ----------\n","  deltaThetas: array of parameters of different clients.\n","\n","  Returns\n","  -------\n","  A dict with updated parameters.\n","  \"\"\"\n","  parameters = None\n","  for i,d in enumerate(deltaThetas):\n","    #ratio = len(trainsets[i])/len(trainset)\n","    ratio = len(trainsets[i])/(len(trainsets[i])*config['K'])\n","    \n","    if i == 0:\n","      parameters = {k:ratio*v for k, v in d.items()}\n","    else:\n","      for (k, v) in d.items():\n","        parameters[k] += ratio * v\n","   \n","  return parameters"]},{"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gTmw78eJ-EW5","outputId":"9bad269e-aa08-45ed-f934-27c805e12b15","trusted":true},"outputs":[],"source":["# Create the artifacts folder for save the artifacts\n","if not path.exists(\"artifacts\"):\n","  os.mkdir(\"artifacts\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Verify the labels specified in the .csv files are coherent with the actual CIFAR-10 labels\n","# see https://github.com/google-research/google-research/issues/924\n","\n","_, labels_mapping = parse_csv(f\"cifar10/federated_train_alpha_{0.0:.2f}.csv\")\n","assert(all(label == labels_mapping[idx] for idx, label in enumerate(trainset.targets)))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for alpha_i, alpha in enumerate(config[\"DIRICHELET_ALPHA\"]):\n","  # Create a dummy model that will hold the server model parameters\n","  net = Net()\n","  net = net.to(device)\n","\n","  optimizer = optim.SGD(net.parameters(), lr=config[\"LR\"], momentum=0.9, weight_decay=1e-3)\n","  scheduler = ReduceLROnPlateau(optimizer, \"min\", factor=0.5, min_lr=1e-6, verbose=True)\n","\n","  # Prepare the training set\n","  if config[\"DATA_DISTRIBUTION\"] == \"iid\":\n","    trainset_len = ( len(trainset) // config[\"NUMBER_OF_CLIENTS\"] ) * config[\"NUMBER_OF_CLIENTS\"]\n","    trainset = torch.utils.data.Subset(trainset, list(range(trainset_len)))\n","\n","    lengths = len(trainset) // config[\"NUMBER_OF_CLIENTS\"] * np.ones(config[\"NUMBER_OF_CLIENTS\"], dtype=int)\n","    trainsets = torch.utils.data.random_split(dataset=trainset, lengths=lengths)\n","  else:\n","    dirichelet_splits, _ = parse_csv(f\"cifar10/federated_train_alpha_{alpha:.2f}.csv\")\n","    trainsets = [torch.utils.data.Subset(trainset, indices) for indices in dirichelet_splits.values()]\n","\n","\n","  # Prepare the validation set\n","  testset_len = ( len(testset) // config[\"NUMBER_OF_CLIENTS\"] ) * config[\"NUMBER_OF_CLIENTS\"]\n","  testset = torch.utils.data.Subset(testset, list(range(testset_len)))\n","\n","  lengths = len(testset) // config[\"NUMBER_OF_CLIENTS\"] * np.ones(config[\"NUMBER_OF_CLIENTS\"], dtype=int)\n","  testsets = torch.utils.data.random_split(dataset=testset, lengths=lengths)\n","\n","  # Instantiate the clients\n","  clientsSizes = torch.zeros(config[\"NUMBER_OF_CLIENTS\"])\n","  clients = list()\n","\n","  for c in range(config[\"NUMBER_OF_CLIENTS\"]):\n","    clients.append(Client(c, trainsets[c], testsets[c], use_data_preloading=use_data_preloading, train_transform=online_train_transform))\n","\n","  if config[\"FED_AVG_M\"]:\n","    old_parameters = {}\n","\n","  # Collect the test accuracies over the epochs\n","  test_accuracies = []\n","\n","  accuracies = list()\n","\n","  # best model\n","  best_model = {}\n","  best_accuracy = 0.0\n","\n","  for step in tqdm(range(config[\"MAX_TIME\"])):\n","    selected_clients = selectClients(config[\"K\"])\n","    #print(f\"Client(s) {[client.i for client in selected_clients]} selected\")\n","\n","    # Collect the updates from the clients\n","    deltaThetas = list()\n","    losses = list()\n","    for i, c in enumerate(selected_clients):\n","      loss, parameters = c.clientUpdate(net.state_dict())\n","      deltaThetas.append(parameters)\n","      losses.append(loss)\n","\n","    g = aggregateClient(deltaThetas)\n","    \n","    # Compute the parameters update\n","    parameters = {}\n","    for (k1, v1), (k2, v2) in zip(net.state_dict().items(), g.items()):\n","      if config[\"FED_AVG_M\"]:\n","        if k1 in old_parameters:\n","          parameters[k1] = v1 - config[\"FED_AVG_M_GAMMA\"] * (config[\"FED_AVG_M_BETA\"] * old_parameters[k1] + v2)  \n","          old_parameters[k1] = config[\"FED_AVG_M_BETA\"] * old_parameters[k1] + v2\n","        else:\n","          parameters[k1] = v1 - config[\"FED_AVG_M_GAMMA\"] * v2\n","          old_parameters[k1] = v2\n","      else:\n","        parameters[k1] = v1 - v2 \n","\n","    # Compute the average accuracy\n","    if step % config[\"LOG_FREQUENCY\"] == 0:\n","      # Evaluate the current server parameters against the validation sets\n","      client_losses_accuracies = [client.compute_accuracy(parameters) for client in clients]\n","      client_losses, client_accuracies = zip(*client_losses_accuracies)\n","      # Average accuracy across the clients\n","      avg_client_accuracy = mean(client_acc for client_acc in client_accuracies)\n","      accuracies.append(avg_client_accuracy * 100)\n","      \n","      # Periodically save the computations done so far\n","      if step % config[\"SAVE_FREQUENCY\"] == 0:\n","        printJSON(alpha, accuracies, net, step)\n","\n","      # Save the model with the best accuracy\n","      if avg_client_accuracy >= best_accuracy:\n","        best_accuracy = avg_client_accuracy\n","        best_model = deepcopy(parameters) # net.state_dict()\n","    # Udate the parameters in the net\n","    net.load_state_dict(parameters)\n","  \n","  # Print the final average accuracy and save the final model  \n","  avg_accuracy = mean(float(client.compute_accuracy(best_model)[1]) for client in clients)\n","  \n","  config[\"AVERAGE_ACCURACY\"][alpha_i] = avg_accuracy\n","  print(f\"Average accuracy with alpha = {alpha} after {step+1} rounds is {avg_accuracy*100:.2f}\")\n","  printJSON(alpha, accuracies, net)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Artifacts"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import shutil\n","shutil.make_archive('artifacts', 'zip', 'artifacts')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":4}
