{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2022-01-20T10:13:55.052022Z","iopub.execute_input":"2022-01-20T10:13:55.052305Z","iopub.status.idle":"2022-01-20T10:13:55.056831Z","shell.execute_reply.started":"2022-01-20T10:13:55.052271Z","shell.execute_reply":"2022-01-20T10:13:55.055613Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"config = {\n    \"EPOCH\" : 300,\n    \"BATCH_SIZE\": 50,\n    \"VALIDATION_BATCH_SIZE\": 5000,\n    \"DEVICE\" : torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n    \"NUM_STEPS\" : 1000\n}","metadata":{"execution":{"iopub.status.busy":"2022-01-20T10:13:55.062394Z","iopub.execute_input":"2022-01-20T10:13:55.062617Z","iopub.status.idle":"2022-01-20T10:13:55.068554Z","shell.execute_reply.started":"2022-01-20T10:13:55.062592Z","shell.execute_reply":"2022-01-20T10:13:55.067776Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, 5)\n        self.conv2 = nn.Conv2d(64, 64, 5)\n        #size = 16 // 4 - 3\n        self.fc1 = nn.Linear(64 * 5 * 5, 384)\n        self.fc2 = nn.Linear(384, 192)\n        self.fc3 = nn.Linear(192, 10)\n\n    def forward(self, x):\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        #x = self.pool(F.relu(self.conv1(x)))\n        #x = self.pool(F.relu(self.conv2(x)))\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x = torch.flatten(x, 1) # flatten all dimensions except batch\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nnet = Net()\nnet = net.to(config[\"DEVICE\"])","metadata":{"execution":{"iopub.status.busy":"2022-01-20T10:13:55.074747Z","iopub.execute_input":"2022-01-20T10:13:55.074961Z","iopub.status.idle":"2022-01-20T10:13:55.095393Z","shell.execute_reply.started":"2022-01-20T10:13:55.074935Z","shell.execute_reply":"2022-01-20T10:13:55.094766Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n])\n\ntrain_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, \n                                        transform=transform)\n\n# train_set, val_set = torch.utils.data.random_split(train_set, [35000, 15000])\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=config[\"BATCH_SIZE\"],\n                                         shuffle=True, num_workers=1)\n\n#val_loader = torch.utils.data.DataLoader(val_set, batch_size=config[\"VALIDATION_BATCH_SIZE\"],\n#                                         shuffle=False, num_workers=1)\n\ntest_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, \n                                        transform=transform)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=config[\"VALIDATION_BATCH_SIZE\"],\n                                         shuffle=False, num_workers=1)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-20T10:13:55.096867Z","iopub.execute_input":"2022-01-20T10:13:55.097175Z","iopub.status.idle":"2022-01-20T10:13:56.649466Z","shell.execute_reply.started":"2022-01-20T10:13:55.097140Z","shell.execute_reply":"2022-01-20T10:13:56.648682Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-3)\n\nscheduler = ReduceLROnPlateau(optimizer, \"min\", verbose=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T10:13:56.651256Z","iopub.execute_input":"2022-01-20T10:13:56.651531Z","iopub.status.idle":"2022-01-20T10:13:56.656904Z","shell.execute_reply.started":"2022-01-20T10:13:56.651495Z","shell.execute_reply":"2022-01-20T10:13:56.656070Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def compute_loss_accuracy(net, dataloader):\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        loss = 0\n        for data in dataloader:\n            images, labels = data\n            images = images.to(config[\"DEVICE\"])\n            labels = labels.to(config[\"DEVICE\"])\n\n            outputs = net(images)\n            loss += criterion(outputs, labels)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n    return loss, 100 * correct / total","metadata":{"execution":{"iopub.status.busy":"2022-01-20T10:13:56.658041Z","iopub.execute_input":"2022-01-20T10:13:56.658722Z","iopub.status.idle":"2022-01-20T10:13:56.670725Z","shell.execute_reply.started":"2022-01-20T10:13:56.658686Z","shell.execute_reply":"2022-01-20T10:13:56.669965Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n\n#running_loss = 0.0\nfor j in tqdm(range(config[\"EPOCH\"])):\n    for i, data in enumerate(train_loader, 0):\n        inputs, labels = data\n        inputs = inputs.to(config[\"DEVICE\"])\n        labels = labels.to(config[\"DEVICE\"])\n        \n        optimizer.zero_grad()\n\n        outputs = net(inputs)\n        train_loss = criterion(outputs, labels)\n        \n        train_loss.backward()\n        optimizer.step()\n    \n    # val_loss, val_acc = compute_loss_accuracy(net, val_loader)\n    test_loss, test_acc = compute_loss_accuracy(net, test_loader)\n    \n    scheduler.step(test_loss)\n    # print(f\"Accuracy after {j + 1} steps on {total} images = {100 * correct / total} (train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, test_loss={test_loss:.4f})\")\n    # print(f\"Epoch {j:3d}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, test_loss={test_loss:.4f}, val_acc={val_acc:.2f}, test_acc={test_acc:.2f}\")\n    print(f\"Epoch {j:3d}: train_loss={train_loss:.4f}, test_loss={test_loss:.4f}, test_acc={test_acc:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-20T10:13:56.673829Z","iopub.execute_input":"2022-01-20T10:13:56.674521Z","iopub.status.idle":"2022-01-20T10:28:50.317391Z","shell.execute_reply.started":"2022-01-20T10:13:56.674446Z","shell.execute_reply":"2022-01-20T10:28:50.316296Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in test_loader:\n        images, labels = data\n        images = images.to(config[\"DEVICE\"])\n        labels = labels.to(config[\"DEVICE\"])\n        \n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f\"Accuracy on {total} images = {100 * correct // total} % with {correct} images classified\")","metadata":{"execution":{"iopub.status.busy":"2022-01-20T10:28:50.318590Z","iopub.status.idle":"2022-01-20T10:28:50.319241Z","shell.execute_reply.started":"2022-01-20T10:28:50.318995Z","shell.execute_reply":"2022-01-20T10:28:50.319022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}