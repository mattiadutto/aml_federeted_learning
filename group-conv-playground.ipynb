{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRyFWIxiPEVX"
   },
   "source": [
    "# Group convolution playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7iCHpO-d0SR",
    "outputId": "48f67bea-3a39-4bf2-ee85-36de1a82dca3"
   },
   "outputs": [],
   "source": [
    "!wget --quiet --no-clobber http://storage.googleapis.com/gresearch/federated-vision-datasets/cifar10.zip\n",
    "!unzip -qq -o cifar10.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "# torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From: https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, *, const_init=None):\n",
    "        super(Net, self).__init__()\n",
    "        # convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "\n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "        if const_init is not None:\n",
    "            for layer in [self.conv1, self.conv2, self.fc1, self.fc2, self.fc3]:\n",
    "                layer.weight.data.fill_(const_init)\n",
    "                layer.bias.data.fill_(const_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x), inplace=True), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x), inplace=True), 2)\n",
    "\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x), inplace=True)\n",
    "        x = F.relu(self.fc2(x), inplace=True)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batched model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Ar1b6p68b3G",
    "outputId": "069527ea-034e-4d5a-c149-8c09594c4b97"
   },
   "outputs": [],
   "source": [
    "class BatchedNet(nn.Module):\n",
    "    def __init__(self, P, *, const_init=None):\n",
    "        super(BatchedNet, self).__init__()\n",
    "\n",
    "        self.P = P\n",
    "\n",
    "        # convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3 * self.P, 6 * self.P, 5, groups=self.P)\n",
    "        self.conv2 = nn.Conv2d(6 * self.P, 16 * self.P, 5, groups=self.P)\n",
    "\n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Conv1d(400 * self.P, 120 * self.P, kernel_size=1, groups=self.P)\n",
    "        self.fc2 = nn.Conv1d(120 * self.P, 84 * self.P, kernel_size=1, groups=self.P)\n",
    "        self.fc3 = nn.Conv1d(84 * self.P, 10 * self.P, kernel_size=1, groups=self.P)\n",
    "\n",
    "        if const_init is not None:\n",
    "            for layer in [self.conv1, self.conv2, self.fc1, self.fc2, self.fc3]:\n",
    "                layer.weight.data.fill_(const_init)\n",
    "                layer.bias.data.fill_(const_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x), inplace=True), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x), inplace=True), 2)\n",
    "\n",
    "        x = x.view(batch_size, -1, 1)\n",
    "        x = F.relu(self.fc1(x), inplace=True)\n",
    "        x = F.relu(self.fc2(x), inplace=True)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10  # number of concurrent clients\n",
    "batch_size = 5\n",
    "\n",
    "net = Net(const_init=0.01)\n",
    "batchedNet = BatchedNet(K, const_init=0.01)\n",
    "\n",
    "# each entry of the images array represents the batch input for one client\n",
    "# images contains tensors of shape (batch_size, n_channels, 32, 32)\n",
    "images = [torch.randn((batch_size, 3, 32, 32)) for _ in range(K)]\n",
    "\n",
    "# stack the images for all the clients\n",
    "# batch is a tensor of shape (batch_size, n_channels * n_clients, 32, 32)\n",
    "# batch[:, 0:3] is the batch input of client 0,\n",
    "# batch[:, 3:6] is the batch input of client 1 and so on...\n",
    "# batch = torch.stack(images).reshape((batch_size, -1, 32, 32))\n",
    "batch = torch.stack(images, dim=1).flatten(1, 2)\n",
    "\n",
    "# verify the images are stacked in the correct way\n",
    "assert all(\n",
    "    torch.allclose(image_from_batch, image)\n",
    "    for image_from_batch, image in zip(torch.chunk(batch, K, dim=1), images)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test convolution\n",
    "\n",
    "Verify the output of a standard convolution applied over all the clients batches is equivalent to the output produced by a grouped convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = nn.Conv2d(3, 6, 5)\n",
    "lbn = nn.Conv2d(3 * K, 6 * K, 5, groups=K)\n",
    "\n",
    "ln.weight.data.fill_(0.01)\n",
    "ln.bias.data.fill_(0.01)\n",
    "\n",
    "lbn.weight.data.fill_(0.01)\n",
    "lbn.bias.data.fill_(0.01)\n",
    "\n",
    "# output of the \"standard\" convolution over each batch\n",
    "output_ln = [ln(ims) for ims in images]\n",
    "\n",
    "output_lbn = lbn(batch)\n",
    "output_lbn = torch.chunk(output_lbn, K, dim=1)\n",
    "\n",
    "assert all(\n",
    "    torch.allclose(out_ln, out_lbn, atol=1e-5)\n",
    "    for out_ln, out_lbn in zip(output_ln, output_lbn)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_first_layer(x):\n",
    "    conv1 = nn.Conv2d(3, 6, 5)\n",
    "    conv2 = nn.Conv2d(6, 16, 5)\n",
    "\n",
    "    conv1.weight.data.fill_(0.01)\n",
    "    conv1.bias.data.fill_(0.01)\n",
    "\n",
    "    conv2.weight.data.fill_(0.01)\n",
    "    conv2.bias.data.fill_(0.01)\n",
    "\n",
    "    x = F.max_pool2d(F.relu(conv1(x)), (2, 2))\n",
    "    x = F.max_pool2d(F.relu(conv2(x)), 2)\n",
    "    return x\n",
    "\n",
    "\n",
    "# compute the output of the first layer of the standard model for each client batch\n",
    "output_first_layer_net = [net_first_layer(client_batch) for client_batch in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 60, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = nn.Conv2d(3 * K, 6 * K, 5, groups=K)\n",
    "c.weight.data.fill_(0)\n",
    "c.bias.data.fill_(1)\n",
    "c(batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_net_first_layer(x):\n",
    "    conv1 = nn.Conv2d(3 * K, 6 * K, 5, groups=K)\n",
    "    conv2 = nn.Conv2d(6 * K, 16 * K, 5, groups=K)\n",
    "\n",
    "    conv1.weight.data.fill_(0.01)\n",
    "    conv1.bias.data.fill_(0.01)\n",
    "\n",
    "    conv2.weight.data.fill_(0.01)\n",
    "    conv2.bias.data.fill_(0.01)\n",
    "\n",
    "    x = F.max_pool2d(F.relu(conv1(x)), (2, 2))\n",
    "    x = F.max_pool2d(F.relu(conv2(x)), 2)\n",
    "    return x\n",
    "\n",
    "\n",
    "# compute the output of the batched model for the single batch\n",
    "output_first_layer_batched_net = batched_net_first_layer(batch)\n",
    "# print(output_first_layer_batched_net.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(\n",
    "    torch.allclose(batched_net_output, net_output, atol=1e-5)\n",
    "    for batched_net_output, net_output in zip(\n",
    "        torch.chunk(output_first_layer_batched_net, K, dim=1), output_first_layer_net\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_second_layer(x):\n",
    "    fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "    fc2 = nn.Linear(120, 84)\n",
    "    fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    fc1.weight.data.fill_(0.01)\n",
    "    fc2.weight.data.fill_(0.01)\n",
    "    fc3.weight.data.fill_(0.01)\n",
    "    fc1.bias.data.fill_(0.01)\n",
    "    fc2.bias.data.fill_(0.01)\n",
    "    fc3.bias.data.fill_(0.01)\n",
    "\n",
    "    x = torch.flatten(x, 1)  # flatten all dimensions except the batch dimension\n",
    "    x = F.relu(fc1(x))\n",
    "    x = F.relu(fc2(x))\n",
    "    x = fc3(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "output_second_layer_net = [net_second_layer(out1) for out1 in output_first_layer_net]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_net_second_layer(x):\n",
    "    fc1 = nn.Conv1d(16 * 5 * 5 * K, 120 * K, kernel_size=1, groups=K)\n",
    "    fc2 = nn.Conv1d(120 * K, 84 * K, kernel_size=1, groups=K)\n",
    "    fc3 = nn.Conv1d(84 * K, 10 * K, kernel_size=1, groups=K)\n",
    "\n",
    "    fc1.weight.data.fill_(0.01)\n",
    "    fc2.weight.data.fill_(0.01)\n",
    "    fc3.weight.data.fill_(0.01)\n",
    "    fc1.bias.data.fill_(0.01)\n",
    "    fc2.bias.data.fill_(0.01)\n",
    "    fc3.bias.data.fill_(0.01)\n",
    "\n",
    "    x = x.view(batch_size, -1, 1)\n",
    "    x = F.relu(fc1(x))\n",
    "    x = F.relu(fc2(x))\n",
    "    x = fc3(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "output_second_layer_batched_net = batched_net_second_layer(\n",
    "    output_first_layer_batched_net\n",
    ").squeeze()\n",
    "output_second_layer_batched_net = torch.chunk(output_second_layer_batched_net, K, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(\n",
    "    torch.allclose(batched_net_output, net_output, atol=1e-5)\n",
    "    for batched_net_output, net_output in zip(\n",
    "        output_second_layer_batched_net, output_second_layer_net\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_net = [net(ims) for ims in images]\n",
    "\n",
    "output_batched_net = batchedNet(batch).squeeze()\n",
    "output_batched_net = torch.chunk(output_batched_net, K, dim=1)\n",
    "\n",
    "\n",
    "assert all(\n",
    "    torch.allclose(o1, o2, atol=1e-5) for o1, o2 in zip(output_net, output_batched_net)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test parameters sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(const_init=None)  # DO NOT initialize weights\n",
    "batchedNet = BatchedNet(K, const_init=None)  # DO NOT initialize weights\n",
    "\n",
    "output_net = [net(ims) for ims in images]\n",
    "\n",
    "output_batched_net = batchedNet(batch).squeeze()\n",
    "output_batched_net = torch.chunk(output_batched_net, K, dim=1)\n",
    "\n",
    "# now, the outputs should not be the same due to the different weights\n",
    "assert all(\n",
    "    torch.allclose(o1, o2, atol=1e-5) == False\n",
    "    for o1, o2 in zip(output_net, output_batched_net)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_parameters = net.state_dict()\n",
    "\n",
    "parameters = {\n",
    "    key: torch.stack([params] * K).flatten(0, 1)\n",
    "    for key, params in reference_parameters.items()\n",
    "}\n",
    "\n",
    "# adjust the size of the fc weights\n",
    "parameters[\"fc1.weight\"] = torch.unsqueeze(parameters[\"fc1.weight\"], -1)\n",
    "parameters[\"fc2.weight\"] = torch.unsqueeze(parameters[\"fc2.weight\"], -1)\n",
    "parameters[\"fc3.weight\"] = torch.unsqueeze(parameters[\"fc3.weight\"], -1)\n",
    "\n",
    "assert all(\n",
    "    torch.allclose(reference_parameters[\"conv1.weight\"], client_parameters)\n",
    "    for client_parameters in torch.chunk(parameters[\"conv1.weight\"], K, dim=0)\n",
    ")\n",
    "assert all(\n",
    "    torch.allclose(reference_parameters[\"fc1.weight\"], client_parameters.squeeze())\n",
    "    for client_parameters in torch.chunk(parameters[\"fc1.weight\"], K, dim=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_net = [net(ims) for ims in images]\n",
    "\n",
    "batchedNet.load_state_dict(parameters)\n",
    "\n",
    "output_batched_net = batchedNet(batch).squeeze()\n",
    "output_batched_net = torch.chunk(output_batched_net, K, dim=1)\n",
    "\n",
    "\n",
    "# now, the outputs should not be the same due to the different weights\n",
    "assert all(\n",
    "    torch.allclose(o1, o2, atol=1e-5) for o1, o2 in zip(output_net, output_batched_net)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(\"cuda\")\n",
    "batchedNet = batchedNet.to(\"cuda\")\n",
    "\n",
    "images = [torch.randn((batch_size, 3, 32, 32), device=\"cuda\") for _ in range(K)]\n",
    "batch = torch.stack(images, dim=1).flatten(1, 2)\n",
    "\n",
    "# wait everything is ready before starting the benchmark\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*         0.42%     139.000us        99.34%      32.674ms      16.337ms       0.000us         0.00%       9.101ms       4.551ms             2  \n",
      "                                            non-batched        12.00%       3.946ms        82.31%      27.073ms      13.537ms       0.000us         0.00%       4.061ms       2.030ms             2  \n",
      "                                      aten::convolution         1.16%     382.000us        41.00%      13.485ms     269.700us       0.000us         0.00%       7.677ms     153.540us            50  \n",
      "                                     aten::_convolution         3.54%       1.164ms        39.84%      13.103ms     262.060us       0.000us         0.00%       7.677ms     153.540us            50  \n",
      "                                           aten::conv2d         0.99%     325.000us        32.11%      10.561ms     240.023us       0.000us         0.00%       5.776ms     131.273us            44  \n",
      "                                aten::cudnn_convolution        17.77%       5.844ms        28.30%       9.307ms     186.140us       7.175ms        78.84%       7.175ms     143.500us            50  \n",
      "                                           aten::linear         1.76%     580.000us        21.19%       6.969ms     116.150us       0.000us         0.00%     924.000us      15.400us            60  \n",
      "                                                batched         1.97%     649.000us        16.36%       5.382ms       2.691ms       0.000us         0.00%       5.040ms       2.520ms             2  \n",
      "                                            aten::addmm        11.48%       3.777ms        15.89%       5.225ms      87.083us     924.000us        10.15%     924.000us      15.400us            60  \n",
      "                                            aten::relu_         4.37%       1.436ms        13.03%       4.285ms      48.693us       0.000us         0.00%     233.000us       2.648us            88  \n",
      "                                       cudaLaunchKernel        12.99%       4.273ms        12.99%       4.273ms       7.826us       0.000us         0.00%       0.000us       0.000us           546  \n",
      "                                           aten::conv1d         0.13%      42.000us        10.01%       3.291ms     548.500us       0.000us         0.00%       1.901ms     316.833us             6  \n",
      "                                       aten::clamp_min_         1.53%     504.000us         8.66%       2.849ms      32.375us       0.000us         0.00%     233.000us       2.648us            88  \n",
      "                                       aten::max_pool2d         1.02%     335.000us         7.45%       2.449ms      55.659us       0.000us         0.00%     267.000us       6.068us            44  \n",
      "                                        aten::clamp_min         5.31%       1.747ms         7.13%       2.345ms      26.648us     233.000us         2.56%     233.000us       2.648us            88  \n",
      "                          aten::max_pool2d_with_indices         5.32%       1.751ms         6.43%       2.114ms      48.045us     267.000us         2.93%     267.000us       6.068us            44  \n",
      "                                             aten::add_         4.07%       1.340ms         5.37%       1.766ms      35.320us     502.000us         5.52%     502.000us      10.040us            50  \n",
      "                                                aten::t         1.47%     483.000us         3.54%       1.164ms      19.400us       0.000us         0.00%       0.000us       0.000us            60  \n",
      "                                            aten::empty         2.32%     762.000us         2.32%     762.000us      12.290us       0.000us         0.00%       0.000us       0.000us            62  \n",
      "                                        aten::transpose         1.52%     501.000us         2.07%     681.000us      11.350us       0.000us         0.00%       0.000us       0.000us            60  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 32.890ms\n",
      "Self CUDA time total: 9.101ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def trace_handler(p):\n",
    "    output = p.key_averages().table(sort_by=\"cpu_time_total\", row_limit=20)\n",
    "    print(output)\n",
    "    p.export_chrome_trace(\"trace.json\")\n",
    "\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "    record_shapes=True,\n",
    "    schedule=torch.profiler.schedule(wait=1, warmup=1, active=2),\n",
    "    on_trace_ready=trace_handler,\n",
    ") as prof:\n",
    "\n",
    "    for i in range(4):\n",
    "        with record_function(\"non-batched\"):\n",
    "            for im in images:\n",
    "                out = net(im)\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        with record_function(\"batched\"):\n",
    "            out = batchedNet(batch)\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        prof.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del net\n",
    "del batchedNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiler trace\n",
    "\n",
    "![Profiler trace](./assets/profiler_trace_grouped_convolutions.png)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "aml.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "030530a5b5034c06a2ebf5849841078c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa7709c7816d40df9aa296e1e5119291",
      "placeholder": "​",
      "style": "IPY_MODEL_411f6851938f49bb908baf2834862b02",
      "value": " 11%"
     }
    },
    "0f66143eafae4524a067a8f3eef958f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2067bf208ecf46b9a94dfc6011c180c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_030530a5b5034c06a2ebf5849841078c",
       "IPY_MODEL_56d1992d773340c99b6356d189e27c9f",
       "IPY_MODEL_9ced7621357e477d9585b460643e378e"
      ],
      "layout": "IPY_MODEL_bc8c722fe3c04a2d8dbadabbf8ee0f1a"
     }
    },
    "411f6851938f49bb908baf2834862b02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "56d1992d773340c99b6356d189e27c9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_caa01c3dfadb4b2380047746071e58d2",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b010f77c90184eb991bb04620e8db909",
      "value": 111
     }
    },
    "9ced7621357e477d9585b460643e378e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f66143eafae4524a067a8f3eef958f3",
      "placeholder": "​",
      "style": "IPY_MODEL_c14cfd47db124418a6289db338d81552",
      "value": " 111/1000 [18:46&lt;2:44:25, 11.10s/it]"
     }
    },
    "aa7709c7816d40df9aa296e1e5119291": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b010f77c90184eb991bb04620e8db909": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bc8c722fe3c04a2d8dbadabbf8ee0f1a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c14cfd47db124418a6289db338d81552": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "caa01c3dfadb4b2380047746071e58d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
