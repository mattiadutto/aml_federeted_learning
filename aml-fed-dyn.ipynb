{"cells":[{"cell_type":"markdown","metadata":{"id":"KRyFWIxiPEVX"},"source":["# Baseline implementation"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-01-17T09:20:00.205470Z","iopub.status.busy":"2022-01-17T09:20:00.204801Z","iopub.status.idle":"2022-01-17T09:20:00.775070Z","shell.execute_reply":"2022-01-17T09:20:00.773923Z","shell.execute_reply.started":"2022-01-17T09:20:00.205331Z"},"trusted":true},"outputs":[],"source":["# download the Cifar10 non-iid splits, if not present\n","\n","from os import path\n","import urllib.request\n","import zipfile\n","\n","if not path.exists(\"cifar10\"):\n","    save_path = \"cifar10.zip\"\n","    urllib.request.urlretrieve(\"http://storage.googleapis.com/gresearch/federated-vision-datasets/cifar10_v1.1.zip\", save_path)\n","    \n","    with zipfile.ZipFile(save_path, 'r') as zip_ref:\n","        zip_ref.extractall(\".\")"]},{"cell_type":"code","execution_count":98,"metadata":{"execution":{"iopub.execute_input":"2022-01-17T10:22:51.170927Z","iopub.status.busy":"2022-01-17T10:22:51.170630Z","iopub.status.idle":"2022-01-17T10:22:51.177402Z","shell.execute_reply":"2022-01-17T10:22:51.176433Z","shell.execute_reply.started":"2022-01-17T10:22:51.170893Z"},"trusted":true},"outputs":[],"source":["config = {\n","    \"E\": 1, # number of local epochs\n","    \"K\": 5, # number of clients selected each round # [5, 10, 20]\n","    \"NUMBER_OF_CLIENTS\": 100, # total number of clients\n","    \"MAX_TIME\": 10000,\n","    \"BATCH_SIZE\": 50,\n","    \"VALIDATION_BATCH_SIZE\": 500,\n","    \"LR\": 0.01,\n","    \"DATA_DISTRIBUTION\": \"non-iid\", # \"iid\" | \"non-iid\"\n","    \"DIRICHELET_ALPHA\": [0.00, 0.05, 0.10, 0.20, 0.50, 1.00, 10.00, 100.0],\n","    \"AVERAGE_ACCURACY\": np.zeros(8),\n","    \"FED_AVG_M\": False,\n","    \"FED_AVG_M_BETA\": 0.9,\n","    \"FED_AVG_M_GAMMA\": 1,\n","    \"LR_DECAY\": 0.99,\n","    \"LOG_FREQUENCY\": 5,\n","    \"DEVICE\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n","    \"AUGMENTATION_PROB\": 0.0,\n","    \"ALPHA\": 0.01 # for FedDyn\n","}"]},{"cell_type":"code","execution_count":99,"metadata":{"execution":{"iopub.execute_input":"2022-01-17T10:22:51.678269Z","iopub.status.busy":"2022-01-17T10:22:51.677485Z","iopub.status.idle":"2022-01-17T10:22:51.683892Z","shell.execute_reply":"2022-01-17T10:22:51.682733Z","shell.execute_reply.started":"2022-01-17T10:22:51.678187Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":100,"metadata":{"execution":{"iopub.execute_input":"2022-01-17T10:22:51.877097Z","iopub.status.busy":"2022-01-17T10:22:51.876738Z","iopub.status.idle":"2022-01-17T10:22:51.901215Z","shell.execute_reply":"2022-01-17T10:22:51.900213Z","shell.execute_reply.started":"2022-01-17T10:22:51.877068Z"},"id":"5Ar1b6p68b3G","outputId":"e695f455-87f7-44c6-fe6f-fb6bdf6b300d","trusted":true},"outputs":[],"source":["# From: https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n","class Net(nn.Module):\n","\n","    def __init__(self, *, input_size=32):\n","        super(Net, self).__init__()\n","        # 1 input image channel, 6 output channels, 5x5 square convolution\n","        self.conv1 = nn.Conv2d(3, 64, 5)\n","        self.conv2 = nn.Conv2d(64, 64, 5)\n","        \n","        # output of the conv layer is (w', h') = (w - 5 + 1, h - 5 + 1)\n","        # max_pool2d halves the dimensions (w', h') = (w / 2, h / 2)\n","\n","        # dynamically compute the image size\n","        size = input_size // 4 - 3\n","        self.fc1 = nn.Linear(64 * (size * size), 384)\n","        self.fc2 = nn.Linear(384, 192)\n","        self.fc3 = nn.Linear(192, 10)\n","\n","    def forward(self, x):\n","        # Max pooling over a (2, 2) window\n","        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n","        # If the size is a square, you can specify with a single number\n","        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n","        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","\n","net = Net()\n","net = net.to(device)\n","print(net)"]},{"cell_type":"code","execution_count":101,"metadata":{"execution":{"iopub.execute_input":"2022-01-17T10:22:52.413337Z","iopub.status.busy":"2022-01-17T10:22:52.412884Z","iopub.status.idle":"2022-01-17T10:22:52.548132Z","shell.execute_reply":"2022-01-17T10:22:52.546216Z","shell.execute_reply.started":"2022-01-17T10:22:52.413300Z"},"id":"eCwGFjE5Feil","trusted":true},"outputs":[],"source":["import torch.optim as optim\n","\n","class Client():\n","  def __init__(self, i, train_set, validation_set, *, input_size=32):\n","    self.i = i\n","    self.train_loader = torch.utils.data.DataLoader(train_set, batch_size=config[\"BATCH_SIZE\"],\n","                                         shuffle=True, num_workers=0)\n","    self.validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=config[\"BATCH_SIZE\"],\n","                                         shuffle=False, num_workers=0)\n","    self.net = Net(input_size=input_size)\n","    self.net = self.net.to(device)\n","    # create your optimizer\n","    self.optimizer = optim.SGD(self.net.parameters(), lr=config[\"LR\"])\n","    self.criterion = nn.CrossEntropyLoss()\n","    \n","    self.previous_gradient = {key:torch.zeros(params.shape, device=device) for key, params in self.net.state_dict().items()}\n","    \n","  def clientUpdate(self, alpha, parameters):\n","    self.net.load_state_dict(parameters)\n","\n","    for e in range(config[\"E\"]):\n","      for images, labels in self.train_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # in your training loop:\n","        self.optimizer.zero_grad()   # zero the gradient buffers\n","        output = self.net(images)\n","        \n","        # compute the loss of the model\n","        loss = self.criterion(output, labels)\n","        \n","        # compute the dot product term\n","        loss -= sum(\n","            torch.sum(old_grad * cur_params) \n","            for (old_grad, cur_params) \n","            in zip(self.previous_gradient.values(), self.net.state_dict().values())\n","        )\n","        \n","        loss += (alpha / 2) * sum(\n","            # torch.sum(cur_params * cur_params) \n","            torch.linalg.norm(cur_params.reshape(-1) - old_params.reshape(-1), 2) ** 2\n","            for cur_params, old_params\n","            in zip(self.net.state_dict().values(), parameters.values())\n","        )\n","\n","        loss.backward()\n","        \n","        self.optimizer.step()    # Does the update\n","    \n","    # store the previous gradient\n","    self.previous_gradient = {\n","      key: old_grad - alpha * (cur_params - old_params)\n","      for (key, old_grad), cur_params, old_params in zip(self.previous_gradient.items(), self.net.state_dict().values(), parameters.values())\n","    }\n","\n","    return self.net.state_dict()\n","\n","  def compute_accuracy(self, parameters):\n","    self.net.load_state_dict(parameters)\n","\n","    self.net.train(False)\n","\n","    running_corrects = 0\n","    n = 0\n","    for data, labels in self.validation_loader:\n","        data = data.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = self.net(data)\n","\n","        _, preds = torch.max(outputs.data, 1)\n","\n","        running_corrects += torch.sum(preds == labels.data).data.item()\n","        n += len(preds)\n","\n","    self.net.train(True)\n","                \n","    return running_corrects / n\n"]},{"cell_type":"code","execution_count":104,"metadata":{"execution":{"iopub.execute_input":"2022-01-17T10:22:54.288766Z","iopub.status.busy":"2022-01-17T10:22:54.287907Z","iopub.status.idle":"2022-01-17T10:22:54.296220Z","shell.execute_reply":"2022-01-17T10:22:54.295228Z","shell.execute_reply.started":"2022-01-17T10:22:54.288730Z"},"id":"QcsNecZCVPP-","trusted":true},"outputs":[],"source":["from collections import defaultdict\n","\n","def parse_csv(filename):\n","  splits = defaultdict(lambda: [])\n","  with open(filename) as f:\n","    for line in f:\n","      if not line[0].isdigit():\n","        continue\n","\n","      user_id, image_id, _ = (int(token) for token in line.split(\",\"))\n","      splits[user_id].append(image_id)\n","\n","  return splits\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import time\n","import json\n","import numpy\n","from copy import deepcopy\n","\n","def listToString(l): \n","    return \" \".join(str(l))\n","\n","def printJSON(alpha, acc, net):\n","    timestr = time.strftime(\"%Y_%m_%d-%I_%M_%S_%p\")\n","    artifact_filename = f\"artifacts/server_model-{timestr}\"\n","\n","    # parameters of the trained model\n","    server_model = net.state_dict()\n","    # save the model on the local file system\n","    torch.save(server_model, artifact_filename + \".pth\")\n","    config_copy = deepcopy(config)\n","    config_copy[\"DIRICHELET_ALPHA\"] = listToString(config_copy[\"DIRICHELET_ALPHA\"])\n","    config_copy[\"AVERAGE_ACCURACY\"] = numpy.array2string(config_copy[\"AVERAGE_ACCURACY\"])\n","    config_copy[\"DEVICE\"] = \"\"\n","    data = {\n","        \"config\": config_copy,\n","        \"alpha\": listToString(alpha),\n","        \"accuracy\": acc\n","    }\n","\n","    with open(artifact_filename + \".json\", \"w\") as f:\n","        f.write(json.dumps(data, indent=4))\n","\n","    # If you want to cat the file, my suggestion is to avoid this is a pretty heavy operation at least on my pc\n","    #artifact_filename += \".json\"\n","    #!cat artifact_filename\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-17T10:22:54.858484Z","iopub.status.busy":"2022-01-17T10:22:54.858223Z"},"id":"gTmw78eJ-EW5","outputId":"9bad269e-aa08-45ed-f934-27c805e12b15","trusted":true},"outputs":[],"source":["import torchvision\n","import torchvision.transforms as transforms\n","import numpy as np\n","import random\n","from statistics import mean\n","\n","from tqdm.notebook import tqdm\n","\n","random.seed(42)\n","\n","random_transform = transforms.Compose(\n","    [\n","        transforms.RandomCrop(32, padding=4),\n","        transforms.RandomHorizontalFlip(1),\n","        transforms.ColorJitter(0.9, 0.9)\n","    ]\n",")\n","\n","train_transform = transforms.Compose([\n","  transforms.ToTensor(),\n","  transforms.RandomApply([random_transform], config[\"AUGMENTATION_PROB\"]),\n","  transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262]),\n","])\n","\n","test_transform = transforms.Compose([\n","  transforms.ToTensor(),\n","  transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=train_transform)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=test_transform)\n","\n","\n","if config[\"DATA_DISTRIBUTION\"] == \"iid\":\n","  # split the training set\n","  trainset_len = ( len(trainset) // config[\"NUMBER_OF_CLIENTS\"] ) * config[\"NUMBER_OF_CLIENTS\"]\n","  trainset = torch.utils.data.Subset(trainset, list(range(trainset_len)))\n","\n","  lengths = len(trainset) // config[\"NUMBER_OF_CLIENTS\"] * np.ones(config[\"NUMBER_OF_CLIENTS\"], dtype=int)\n","  trainsets = torch.utils.data.random_split(dataset=trainset, lengths=lengths)\n","else:\n","  dirichelet_splits = parse_csv(f\"cifar10/federated_train_alpha_{config['DIRICHELET_ALPHA']:.2f}.csv\")\n","  trainsets = [torch.utils.data.Subset(trainset, indices) for indices in dirichelet_splits.values()]\n","\n","\n","# split the validation set\n","testset_len = ( len(testset) // config[\"NUMBER_OF_CLIENTS\"] ) * config[\"NUMBER_OF_CLIENTS\"]\n","testset = torch.utils.data.Subset(testset, list(range(testset_len)))\n","\n","lengths = len(testset) // config[\"NUMBER_OF_CLIENTS\"] * np.ones(config[\"NUMBER_OF_CLIENTS\"], dtype=int)\n","testsets = torch.utils.data.random_split(dataset=testset, lengths=lengths)\n","\n","\n","clientsSizes = torch.zeros(config[\"NUMBER_OF_CLIENTS\"])\n","clients = list()\n","\n","def selectClients(k):\n","  return random.choices(clients, k=k)\n","\n","def aggregateClient(deltaThetas):\n","  parameters = None\n","  for i,d in enumerate(deltaThetas):\n","    #ratio = len(trainsets[i])/len(trainset)\n","    ratio = len(trainsets[i])/(len(trainsets[i])*config['K'])\n","    \n","    if i == 0:\n","      parameters = {k:ratio*v for k, v in d.items()}\n","    else:\n","      for (k, v) in d.items():\n","        parameters[k] += ratio * v\n","   \n","  return parameters\n","\n","for c in range(config[\"NUMBER_OF_CLIENTS\"]):\n","  clients.append(Client(c, trainsets[c], testsets[c]))\n","\n","# initial learning rate\n","lr = config[\"LR\"]\n","\n","# initial alpha_i value\n","alpha_i = config[\"DIRICHELET_ALPHA\"][0]\n","\n","# collect the test accuracies over the epochs\n","test_accuracies = []\n","\n","# initialize h_0\n","h = {key:torch.zeros(params.shape, device=device) for key, params in net.state_dict().items()}\n","\n","m = config[\"NUMBER_OF_CLIENTS\"]\n","alpha = config[\"ALPHA\"]\n","K = config[\"K\"]\n","\n","accuracies = list()\n","\n","for step in tqdm(range(config[\"MAX_TIME\"])):\n","#for t in range(MAX_TIME):\n","  selected_clients = selectClients(K)\n","  #print(f\"Client(s) {[client.i for client in selected_clients]} selected\")\n","\n","  thetas = list()\n","  for i, c in enumerate(selected_clients):\n","    thetas.append(c.clientUpdate(alpha, net.state_dict()))\n","  \n","  h = {\n","    key: prev_h - alpha * 1 / m * sum(theta[key] - old_params for theta in thetas)\n","    for (key, prev_h), old_params in zip(h.items(), net.state_dict().values())\n","  }\n","\n","  new_parameters = {\n","    key: (1 / K) * sum(theta[key] for theta in thetas)\n","    for key in net.state_dict().keys()\n","  }\n","\n","  new_parameters = {\n","    key: params - (1 / alpha) * h_params\n","    for (key, params), h_params in zip(new_parameters.items(), h.values())\n","  }\n","\n","  net.load_state_dict(new_parameters)\n","\n","  if step % config[\"LOG_FREQUENCY\"] == 0:\n","    client_losses_accuracies = [client.compute_accuracy(new_parameters) for client in clients]\n","    client_losses, client_accuracies = zip(*client_losses_accuracies)\n","    \n","    avg_client_accuracy = mean(client_acc for client_acc in client_accuracies)\n","    accuracies.append(avg_client_accuracy * 100)\n","    print(f\"Average accuracy after {step} rounds is {avg_client_accuracy*100}\")\n","\n","  avg_accuracy = mean(float(client.compute_accuracy(new_parameters)[1]) for client in clients)\n","\n","  config[\"AVERAGE_ACCURACY\"][alpha_i] = avg_accuracy\n","  print(f\"Average accuracy with alpha = {alpha} after {step+1} rounds is {avg_accuracy*100}\")\n","  printJSON(alpha, accuracies, net)\n","\n","!zip -r artifacts.zip ./artifacts # For save the folder on Kaggle"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
