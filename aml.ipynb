{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRyFWIxiPEVX"
      },
      "source": [
        "# Baseline implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN9_GO3YcGI9",
        "outputId": "a9253aba-1ae2-4cd3-f469-09b4f95b4d78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 48.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 46.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install wandb --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://storage.googleapis.com/gresearch/federated-vision-datasets/cifar10.zip\n",
        "!unzip cifar10.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7iCHpO-d0SR",
        "outputId": "4628f881-d985-4e13-c3fa-0fb7ca9d68f0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-29 09:14:02--  http://storage.googleapis.com/gresearch/federated-vision-datasets/cifar10.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.152.128, 142.250.136.128, 209.85.200.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.152.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1627997 (1.6M) [application/zip]\n",
            "Saving to: ‘cifar10.zip’\n",
            "\n",
            "\rcifar10.zip           0%[                    ]       0  --.-KB/s               \rcifar10.zip         100%[===================>]   1.55M  --.-KB/s    in 0.008s  \n",
            "\n",
            "2021-12-29 09:14:02 (189 MB/s) - ‘cifar10.zip’ saved [1627997/1627997]\n",
            "\n",
            "Archive:  cifar10.zip\n",
            "   creating: cifar10/\n",
            "  inflating: cifar10/federated_train_alpha_0.00.csv  \n",
            "  inflating: cifar10/test.csv        \n",
            "  inflating: cifar10/federated_train_alpha_10.00.csv  \n",
            "  inflating: cifar10/federated_train_alpha_0.05.csv  \n",
            "  inflating: cifar10/federated_train_alpha_100.00.csv  \n",
            "  inflating: cifar10/federated_train_alpha_0.10.csv  \n",
            "  inflating: cifar10/federated_train_alpha_0.20.csv  \n",
            "  inflating: cifar10/federated_train_alpha_1.00.csv  \n",
            "  inflating: cifar10/federated_train_alpha_0.50.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "X82NHRCAcXLl",
        "outputId": "e905e8fa-c036-45a2-8143-0155d6626124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpeiro98\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/aml-federated-learning/step-2/runs/x40uwyvc\" target=\"_blank\">comic-violet-41</a></strong> to <a href=\"https://wandb.ai/aml-federated-learning/step-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fbc10b9aa10>"
            ],
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/aml-federated-learning/step-2/runs/x40uwyvc?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init(project=\"step-2\", entity=\"aml-federated-learning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ww5uiZ6HfmBd"
      },
      "outputs": [],
      "source": [
        "E = 2\n",
        "STEP_SIZE = 5\n",
        "GAMMA = 0.1\n",
        "\n",
        "# K = 1, NUMBE_OR_CLIENTS = 2, MAX_TIME = 3 -> 58 sec\n",
        "\n",
        "K = 10 # to set\n",
        "NUMBER_OF_CLIENTS = 100 # to set\n",
        "MAX_TIME = 20 #to set\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "lr = 0.05\n",
        "\n",
        "DATA_DISTRIBUTION = \"non-iid\" # \"iid\" | \"non-iid\"\n",
        "DIRICHELET_ALPHA = 0.1 # 0.00, 0.05, 0.10, 0.20, 0.50, 1.00, 10.00, 100.0\n",
        "\n",
        "assert(DATA_DISTRIBUTION == \"iid\" or NUMBER_OF_CLIENTS == 100)\n",
        "\n",
        "wandb.config.update({\n",
        "    \"batch-size\": batch_size,\n",
        "    \"learning-rate\": lr,\n",
        "    # \"momentum\": MOMENTUM,\n",
        "    # \"weight_decay\": WEIGHT_DECAY,\n",
        "    \"num_epochs\": E,\n",
        "    \"step_size\": STEP_SIZE,\n",
        "    \"gamma\": GAMMA,\n",
        "    \"K\": K,\n",
        "    \"number_of_clients\": NUMBER_OF_CLIENTS,\n",
        "    \"max_time\": MAX_TIME,\n",
        "    \"data_distribution\": DATA_DISTRIBUTION,\n",
        "    \"dirichelet_alpha\": DIRICHELET_ALPHA\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ar1b6p68b3G",
        "outputId": "d8de7c53-d1d3-434a-e72a-97d0739b6121"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# From: https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square, you can specify with a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net = net.to(\"cuda\")\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "eCwGFjE5Feil"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "class Client():\n",
        "  def __init__(self, i, train_set, validation_set):\n",
        "    self.i = i\n",
        "    self.train_set = train_set\n",
        "    self.batch_size = 32\n",
        "    self.train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "    self.validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "    self.net = Net()\n",
        "    self.net = self.net.to(\"cuda\")\n",
        "    # create your optimizer\n",
        "    self.optimizer = optim.SGD(self.net.parameters(), lr=lr)\n",
        "    self.criterion = nn.CrossEntropyLoss()\n",
        "    # self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "    wandb.watch(self.net, criterion=self.criterion, log_freq=100, log_graph=True)\n",
        "    \n",
        "  def clientUpdate(self, parameters):\n",
        "    self.net.load_state_dict(parameters)\n",
        "    theta = parameters\n",
        "    for e in range(E):\n",
        "      for images, labels in self.train_loader:\n",
        "        images = images.to(\"cuda\")\n",
        "        labels = labels.to(\"cuda\")\n",
        "        # in your training loop:\n",
        "        self.optimizer.zero_grad()   # zero the gradient buffers\n",
        "        output = self.net(images)\n",
        "        loss = self.criterion(output, labels)\n",
        "        loss.backward()\n",
        "        wandb.log({f\"client-loss-{self.i}\": loss.item()})\n",
        "        self.optimizer.step()    # Does the update\n",
        "    \n",
        "    return_dict = {}\n",
        "    for (k1, v1), (k2, v2) in zip(parameters.items(), self.net.state_dict().items()):\n",
        "      return_dict[k1] = v1 - v2\n",
        "    return return_dict\n",
        "\n",
        "  def compute_accuracy(self, parameters):\n",
        "    self.net.load_state_dict(parameters)\n",
        "\n",
        "    running_corrects = 0\n",
        "    n = 0\n",
        "    for data, labels in self.validation_loader:\n",
        "        data = data.to(\"cuda\")\n",
        "        labels = labels.to(\"cuda\")\n",
        "\n",
        "        outputs = self.net(data)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        n += len(preds)\n",
        "                \n",
        "    return running_corrects / n\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def parse_csv(filename):\n",
        "  splits = defaultdict(lambda: [])\n",
        "  with open(filename) as f:\n",
        "    for line in f:\n",
        "      if not line[0].isdigit():\n",
        "        continue\n",
        "\n",
        "      user_id, image_id, _ = (int(token) for token in line.split(\",\"))\n",
        "      splits[user_id].append(image_id)\n",
        "\n",
        "  return splits\n"
      ],
      "metadata": {
        "id": "QcsNecZCVPP-"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTmw78eJ-EW5",
        "outputId": "a82ea23b-9940-470c-8375-edeeabc759ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client(s) [63, 2, 27, 22, 73, 67, 89, 8, 42, 2] selected\n",
            "Client(s) [21, 50, 2, 19, 64, 54, 22, 58, 80, 0] selected\n",
            "Client(s) [80, 69, 34, 15, 95, 33, 9, 9, 84, 60] selected\n",
            "Client(s) [80, 72, 53, 97, 37, 55, 82, 61, 86, 57] selected\n",
            "Client(s) [70, 4, 22, 28, 7, 23, 10, 27, 63, 36] selected\n",
            "Client(s) [37, 20, 26, 93, 64, 60, 17, 72, 16, 37] selected\n",
            "Client(s) [98, 63, 55, 68, 84, 77, 22, 3, 31, 26] selected\n",
            "Client(s) [21, 94, 87, 31, 65, 39, 91, 45, 26, 24] selected\n",
            "Client(s) [56, 26, 58, 89, 39, 21, 99, 50, 9, 4] selected\n",
            "Client(s) [10, 62, 79, 42, 6, 38, 99, 52, 97, 86] selected\n",
            "Client(s) [1, 72, 68, 53, 26, 64, 11, 43, 45, 95] selected\n",
            "Client(s) [87, 26, 50, 17, 91, 87, 29, 63, 60, 15] selected\n",
            "Client(s) [76, 53, 77, 53, 0, 32, 1, 92, 87, 83] selected\n",
            "Client(s) [30, 5, 87, 94, 8, 48, 6, 76, 76, 12] selected\n",
            "Client(s) [47, 54, 26, 87, 42, 21, 53, 72, 20, 31] selected\n",
            "Client(s) [99, 64, 43, 51, 12, 22, 33, 58, 23, 22] selected\n",
            "Client(s) [7, 63, 22, 90, 85, 7, 23, 66, 21, 13] selected\n",
            "Client(s) [93, 57, 47, 78, 80, 19, 9, 43, 42, 46] selected\n",
            "Client(s) [72, 67, 98, 9, 40, 33, 86, 24, 19, 44] selected\n",
            "Client(s) [42, 27, 24, 92, 44, 86, 55, 5, 99, 83] selected\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform = transform)\n",
        "\n",
        "\n",
        "if DATA_DISTRIBUTION == \"iid\":\n",
        "  # split the training set\n",
        "  trainset_len = ( len(trainset) // NUMBER_OF_CLIENTS ) * NUMBER_OF_CLIENTS\n",
        "  print(trainset_len)\n",
        "  trainset = torch.utils.data.Subset(trainset, list(range(trainset_len)))\n",
        "\n",
        "  lengths = len(trainset) // NUMBER_OF_CLIENTS * np.ones(NUMBER_OF_CLIENTS, dtype=np.int)\n",
        "  print(lengths)\n",
        "  trainsets = torch.utils.data.random_split(dataset=trainset, lengths=lengths)\n",
        "else:\n",
        "  dirichelet_splits = parse_csv(f\"cifar10/federated_train_alpha_{DIRICHELET_ALPHA:.2f}.csv\")\n",
        "  trainsets = [torch.utils.data.Subset(trainset, indices) for indices in dirichelet_splits.values()]\n",
        "\n",
        "\n",
        "# split the validation set\n",
        "testset_len = ( len(testset) // NUMBER_OF_CLIENTS ) * NUMBER_OF_CLIENTS\n",
        "print(testset_len)\n",
        "testset = torch.utils.data.Subset(testset, list(range(testset_len)))\n",
        "\n",
        "lengths = len(testset) // NUMBER_OF_CLIENTS * np.ones(NUMBER_OF_CLIENTS, dtype=np.int)\n",
        "# print(lengths)\n",
        "testsets = torch.utils.data.random_split(dataset=testset, lengths=lengths)\n",
        "\n",
        "\n",
        "clientsSizes = torch.zeros(NUMBER_OF_CLIENTS)\n",
        "clients = list()\n",
        "\n",
        "def selectClients(k):\n",
        "  return random.choices(clients, k=k)\n",
        "\n",
        "def aggregateClient(deltaThetas):\n",
        "  parameters = None\n",
        "  for i,d in enumerate(deltaThetas):\n",
        "    ratio = len(trainsets[i])/len(trainset)\n",
        "    \n",
        "    if i == 0:\n",
        "      parameters = {k:ratio*v for k, v in d.items()}\n",
        "    else:\n",
        "      for (k, v) in d.items():\n",
        "        parameters[k] += ratio * v\n",
        "   \n",
        "  return parameters\n",
        "\n",
        "for c in range(NUMBER_OF_CLIENTS):\n",
        "  clients.append(Client(c, trainsets[c], testsets[c]))\n",
        "\n",
        "\n",
        "for t in range(MAX_TIME):\n",
        "  selected_clients = selectClients(K)\n",
        "  print(f\"Client(s) {[client.i for client in selected_clients]} selected\")\n",
        "\n",
        "  deltaThetas = list()\n",
        "  for i, c in enumerate(selected_clients):\n",
        "    deltaThetas.append(c.clientUpdate(net.state_dict()))\n",
        "    \n",
        "  g = aggregateClient(deltaThetas)\n",
        "  \n",
        "  parameters = {}\n",
        "  for (k1, v1), (k2, v2) in zip(net.state_dict().items(), g.items()):\n",
        "    parameters[k1] = v1 - v2 # todo: add server learning rate gamma\n",
        "  net.load_state_dict(parameters)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "print(Counter(label for _, label in iter(trainsets[0])))\n",
        "print(Counter(label for _, label in iter(trainsets[1])))\n",
        "print(Counter(label for _, label in iter(trainsets[2])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj2oqawRbnF-",
        "outputId": "0bd802ad-49b0-4a41-bd70-31ab52999a7a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({1: 248, 5: 36, 4: 33, 9: 31, 6: 29, 2: 29, 8: 28, 3: 22, 7: 22, 0: 22})\n",
            "Counter({6: 222, 3: 35, 7: 35, 8: 34, 9: 32, 5: 32, 1: 28, 0: 28, 4: 27, 2: 27})\n",
            "Counter({6: 199, 5: 41, 3: 40, 9: 39, 8: 37, 7: 34, 1: 33, 0: 29, 4: 25, 2: 23})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utb7E9snmQwi",
        "outputId": "a4136e09-995c-445a-f318-49efc03de056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy after 20 rounds is 0.1067\n"
          ]
        }
      ],
      "source": [
        "from statistics import mean\n",
        "\n",
        "model_parameters = net.state_dict()\n",
        "avg_accuracy = mean(client.compute_accuracy(model_parameters) for client in clients)\n",
        "\n",
        "print(f\"Average accuracy after {MAX_TIME} rounds is {avg_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "4yo5tYPNmxQz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8b88bd330db6447ab67a1ab1eaa1e8a3",
            "d1d26613fae14b55ba58e93089f74cbd",
            "2856de2329954b77aa190e7fa6cfba5f",
            "39bfea5fd5134fcab9c13cc06c6ad443",
            "e6be789085b74552a74d333e807ff3ef",
            "01461636fc5945a9b70a375614104961",
            "011eb236e2df4a64a79e637685a6a3fe",
            "a81b7e73924d4bcf89495124dc5bf1b9"
          ]
        },
        "outputId": "19502319-a11d-4ed2-f38b-5341d98bbd2a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 10323... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b88bd330db6447ab67a1ab1eaa1e8a3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.35MB of 0.35MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>client-loss-0</td><td>▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▃▄▄▃▂▄▄▄▄▄▃▄▄▂▁█▄▄▄▄▃▄▄▃▃</td></tr><tr><td>client-loss-1</td><td>▅▅▅▅▄▄▅▅▄▃▅▅▅▅▃▂▆▅▂▁▅▅▅▅▄▄▅▅▄▃▅▅▅▅▂▁█▅▃▂</td></tr><tr><td>client-loss-10</td><td>████████▇▇████▇▆██▆▅████████▇▆████▆▅██▄▁</td></tr><tr><td>client-loss-11</td><td>▆▆▆▆▅▅▅▅▄▂█▆▆▅▄▃▆▆▃▁</td></tr><tr><td>client-loss-12</td><td>▄▄▄▄▄▄▄▄▃▃▅▅▄▄▃▁█▄▃▃▄▄▄▄▄▄▄▄▃▂▅▅▄▄▃▁█▄▃▃</td></tr><tr><td>client-loss-13</td><td>▄▄▄▄▄▃▃▄▂▁█▄▄▄▄▃▄▄▃▃</td></tr><tr><td>client-loss-15</td><td>▇██▇▇▇▇█▇▆▇██▇▇▆▇█▆▅▇▇█▇▇▇▇▇▆▅▇█▇█▆▄▆█▅▁</td></tr><tr><td>client-loss-16</td><td>▇▇▇▇█▇▇▇▆▅▇▇█▇▅▄▇▆▃▁</td></tr><tr><td>client-loss-17</td><td>▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▆▆▅▄▆▆▆▆▆▆▆▆▅▃█▆▆▆▅▄▆▆▃▁</td></tr><tr><td>client-loss-19</td><td>▅▅▅▅▅▅▄▅▅▅▄▅▄▄▅▅▅▄▅▃█▅▅▄▅▅▁▅▅▅▄▅▃▁▅▅▄▃▅▁</td></tr><tr><td>client-loss-2</td><td>██▇▇▆█▄█▇▇▃▆▄▁█▇▇▆█▆██▇▅▆█▁█▇▇▅▆▆▄█▇▅▃█▁</td></tr><tr><td>client-loss-20</td><td>▅▅▅▅▅▅▅▅▄▄▅▅▅▅▄▄▅▅▃▃▅▅▅▅▅▄▅▅▃▂▆▅▅▅▂▁█▅▃▁</td></tr><tr><td>client-loss-21</td><td>▇▇▆▇▇▇▅▇▇▇▆▇▇▇▅▅▇▇▆▆▇▇▅▄▇▇▇▅▇▇█▃▇▇▇▅▇▇█▁</td></tr><tr><td>client-loss-22</td><td>████▆███▇█▆▆██▇██████▅██▅▂█▃▁██▂██████▃▁</td></tr><tr><td>client-loss-23</td><td>▄▄▄▄▄▄▄▄▄▄▄▄▃▃▄▄▄▃▄▃█▄▄▄▄▄▂▄▄▄▃▅▃▁▄▄▄▃▄▂</td></tr><tr><td>client-loss-24</td><td>▅▅▅▅▅▅▄▅▅▅▄▄▃▂▅▅▅▄▅▃█▅▅▄▄▅▁▅▅▅▄▄▃▂▅▅▄▃▅▁</td></tr><tr><td>client-loss-26</td><td>████▆███▇█▆▄██▆██████▄██▇▅█▃▂██▄██████▅▁</td></tr><tr><td>client-loss-27</td><td>████▇█▇▇██▆▇▆▅██▇▇█▇▇██▆▆█▁██▇▅▆▅▁██▇▆█▄</td></tr><tr><td>client-loss-28</td><td>█▇▇▇█▇▇▇▇▆▇█▇▇▅▅▇▇▃▁</td></tr><tr><td>client-loss-29</td><td>▅▅▅▅▅▄▅▅▃▂▅▅▅▅▃▁█▅▃▁</td></tr><tr><td>client-loss-3</td><td>█████▇██▆▆████▅▄█▇▃▁</td></tr><tr><td>client-loss-30</td><td>▄▄▄▄▄▃▄▄▃▁█▄▄▄▄▃▄▄▃▂</td></tr><tr><td>client-loss-31</td><td>▇▇▇▇▇▇▆▇▇▇▅▇▄▁▇▇▇▇▇▆▇▇▇▅█▆▁▇▇▇▆▇▄▁▇▇▇▆▇▆</td></tr><tr><td>client-loss-32</td><td>▆▆▆▇▇▆▇▆▆▅▇▆▇▆▅▃█▇▄▁</td></tr><tr><td>client-loss-33</td><td>▄▄▄▄▄▄▄▄▄▄▃▄▃▃▄▄▄▃▄▃█▄▄▄▄▄▂▄▄▄▃▅▃▁▄▄▄▃▄▁</td></tr><tr><td>client-loss-34</td><td>▇▇▇▇█▇▇▇▆▅▇▇▇▇▅▄▇▇▂▁</td></tr><tr><td>client-loss-36</td><td>▇▇▇▇█▇▇▇▇▆▇▇▇▇▅▃▇█▄▁</td></tr><tr><td>client-loss-37</td><td>██████▇███▆█▅▄█████▇███▆█▇▁█████▇▆██▆▅▇▁</td></tr><tr><td>client-loss-38</td><td>▇▇▇▇▇▇▇▇▆▅▇▇▇▇▅▃▇█▃▁</td></tr><tr><td>client-loss-39</td><td>▅▅▅▅▄▄▅▅▄▃▄▅▅▄▃▁▇▅▃▂▅▅▅▅▄▄▅▅▄▃▄▅▅▄▃▁█▅▄▃</td></tr><tr><td>client-loss-4</td><td>▇█▇█▇▇▇█▇▆▇█▇▇▆▆▇█▅▅▇█▇██▇▇█▆▆▇█▇▇▆▄▇█▄▁</td></tr><tr><td>client-loss-40</td><td>▅▅▅▅▅▄▅▅▄▁█▅▅▅▄▃▅▆▃▁</td></tr><tr><td>client-loss-42</td><td>▇▇▆▇▇▇▆▆▇▇▆▇▇▆▄▃▇▇▆▅▇▆▃▂▇▇▇▄▇▆█▂▇▇▇▃▇▆▇▁</td></tr><tr><td>client-loss-43</td><td>▄▄▄▄▄▄▃▄▄▄▃▅▂▁▄▄▄▄▄▃█▄▄▄▄▄▃▄▄▄▄▄▃▁▄▄▄▄▄▃</td></tr><tr><td>client-loss-44</td><td>▄▄▄▄▄▄▄▄▂▁█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▄▄▂▁█▄▄▄▄▄▄▄▄▄</td></tr><tr><td>client-loss-45</td><td>▅▅▅▅▆▅▅▅▅▄▅▅▆▅▄▄▆▅▃▁▅▅▅▅▆▅▅▅▄▃▆▆▆▅▃▂█▅▃▁</td></tr><tr><td>client-loss-46</td><td>▆▆▆▆▆▅▆▆▄▃█▆▆▆▅▃▆▆▃▁</td></tr><tr><td>client-loss-47</td><td>▆▆▆▆▇▆▆▆▅▄▇▆▇▆▅▃▇▇▄▁▆▆▆▆▆▆▆▆▅▃█▆▇▆▅▃▇▇▄▁</td></tr><tr><td>client-loss-48</td><td>▆▆▆▆▆▅▆▆▅▃▇▇▆▆▄▂█▆▃▁</td></tr><tr><td>client-loss-5</td><td>▄▄▄▄▄▃▄▄▃▁█▄▄▄▄▃▄▄▃▃▄▄▄▄▄▃▅▄▃▁▇▄▄▄▃▃▄▄▃▂</td></tr><tr><td>client-loss-50</td><td>██████▇███▇█▆▆███▇▇▇███▆█▇▂███▇█▆▅██▅▅▆▁</td></tr><tr><td>client-loss-51</td><td>▄▄▄▄▄▃▄▄▃▁█▄▄▄▄▃▄▄▃▃</td></tr><tr><td>client-loss-52</td><td>▆▆▆▆▆▅▆▆▄▃█▆▆▅▃▁█▆▃▁</td></tr><tr><td>client-loss-53</td><td>▇▇▇▇▇▇▅▇▇▇▆▇▇▇▂▄▇▇▆▅█▇▂▄▇▇▆▅▇▇▇▄▇▇▆▅▇▇▆▁</td></tr><tr><td>client-loss-54</td><td>▆▆▆▆▆▆▆▆▆▅▆▆▆▆▅▅▆▆▅▄▆▆▆▆▆▅▆▆▄▃▇▆▆▆▄▂█▆▃▁</td></tr><tr><td>client-loss-55</td><td>██████▇███▆▇▆▅███▇█▇███▆▇█▂███▅█▅▁██▇▆█▄</td></tr><tr><td>client-loss-56</td><td>▇▇▇▇▇▆▇▇▆▅▇▇▇▆▄▂█▇▃▁</td></tr><tr><td>client-loss-57</td><td>▆▆▇▆▆▆▆▆▆▅▆▇▇▆▅▅▆▆▅▄▆▆▆▆▆▅▆▆▄▂█▇▇▆▄▂█▇▃▁</td></tr><tr><td>client-loss-58</td><td>██████▇███▆█▆▅███▇█▇███▅██▁███▆█▅▂██▄▁█▁</td></tr><tr><td>client-loss-6</td><td>▅▅▅▅▆▅▆▅▅▄▆▅▆▅▄▃▇▅▃▁▅▅▅▅▆▅▆▅▄▃█▅▅▅▄▃▇▅▃▁</td></tr><tr><td>client-loss-60</td><td>▇▇▇██▇▇▇▇▇▆█▆▄▇▇█▇▇▇▇▇▇▆██▂▇▇▇▆█▆▃██▄▁█▂</td></tr><tr><td>client-loss-61</td><td>█████▇█▇▆▅████▅▄█▇▂▁</td></tr><tr><td>client-loss-62</td><td>████▇▇██▆▆▇███▅▄██▄▁</td></tr><tr><td>client-loss-63</td><td>▇▇▆▇▇▆▅▆▇▇▆▆▇▆▅▃▇▇▆▆▇▆▃▁▇▆▇▃▇▆▇▄▆▆█▁▇▆▆▄</td></tr><tr><td>client-loss-64</td><td>▇▇▇▇▆▇▇▆▇▅▇▇▇▇▆▇▇▆▇▅▇▇▇▇▆▇▇▅▇▃▇▇▇▇▅█▇▄█▁</td></tr><tr><td>client-loss-65</td><td>▇▇▇▇█▇▇▇▇▆█▇█▇▆▄▆█▅▁</td></tr><tr><td>client-loss-66</td><td>▆▆▆▆▆▅▆▆▅▃█▆▆▆▄▁█▇▄▁</td></tr><tr><td>client-loss-67</td><td>▅▅▅▅▄▄▅▄▄▄▅▅▅▅▄▄▅▄▃▃▅▅▅▅▄▄▅▄▃▁█▅▅▅▄▃▅▄▂▁</td></tr><tr><td>client-loss-68</td><td>▅▅▅▅▅▄▅▅▄▄▅▅▅▄▃▃▅▄▂▁▅▅▅▅▅▄▅▄▄▃▅▅▅▄▃▁█▄▃▂</td></tr><tr><td>client-loss-69</td><td>▇▇▇██▇▇▇▇▆█▇▇▇▅▄▇▇▃▁</td></tr><tr><td>client-loss-7</td><td>▅▅▅▅▅▅▄▅▅▅▄▅▄▃▅▅▅▄▄▃█▅▅▄▅▄▁▅▅▅▄▅▃▂▅▅▄▄▄▁</td></tr><tr><td>client-loss-70</td><td>████▇▇██▇▆███▇▅▅██▄▁</td></tr><tr><td>client-loss-72</td><td>▇▇▇▇▇▇▅▇▇▇▇▇▇▇▅▄▇▇▆▅█▇▁▄▇▇▇▄▇▇█▃▇▇█▃▇▇▇▁</td></tr><tr><td>client-loss-73</td><td>█▇▇██▇▇▇▆▅█▇█▇▄▄▇▆▂▁</td></tr><tr><td>client-loss-76</td><td>▄▄▄▄▄▄▁▇▄▄▃▄▂▁▄▄▄▃▄▃█▄▄▄▄▄▂▄▄▄▃▄▃▁▄▄▄▃▄▂</td></tr><tr><td>client-loss-77</td><td>▆▆▆▆▆▅▆▆▅▅▆▆▆▆▄▄▅▅▃▂▆▆▆▆▆▅▅▆▄▃█▆▆▅▄▃▆▆▃▁</td></tr><tr><td>client-loss-78</td><td>▄▄▄▄▄▃▄▄▃▁█▄▄▄▄▃▄▄▃▂</td></tr><tr><td>client-loss-79</td><td>████▇▇██▆▅████▅▄██▃▁</td></tr><tr><td>client-loss-8</td><td>▅▅▅▅▅▅▅▅▅▄▅▅▅▅▄▄▅▅▄▄▅▅▅▅▅▄▅▅▄▃▆▅▅▅▃▁█▅▃▂</td></tr><tr><td>client-loss-80</td><td>▃▂▂▂▂▃▂▂▂▁▃▂▂▂▂▃▂▂▂▁▃▂▂▂▂▃▂▂▂▁▂▂▂▂▁█▂▂▂▂</td></tr><tr><td>client-loss-82</td><td>██▇█▇▆▇▇▅▄██▇█▄▃▅▇▃▁</td></tr><tr><td>client-loss-83</td><td>▅▄▄▅▄▄▄▄▃▂▆▅▅▄▃▂▆▄▃▁▄▄▄▄▄▃▅▄▃▁█▄▄▄▄▄▄▄▃▂</td></tr><tr><td>client-loss-84</td><td>▇▇▇█▇▆██▅▅▇▇▇▇▄▄██▃▂▇▇▇█▇▆██▅▄▇▇▇▇▄▃██▂▁</td></tr><tr><td>client-loss-85</td><td>▄▄▄▄▄▃▄▄▃▁█▄▄▄▄▃▄▄▃▃</td></tr><tr><td>client-loss-86</td><td>▅▅▅▅▅▅▅▄▅▄▅▅▅▅▄▆▆▄▅▃▅▅▅▅▃█▅▃▇▃▅▅▅▅▃█▅▃▇▁</td></tr><tr><td>client-loss-87</td><td>▄▄▄▃▄▂▃▄▄▄▇▄▄▃▄▃▃▄▄▄▄▄▄█▄▄▃▄▃▃▄▄▄▄▄▄▁▄▃▃</td></tr><tr><td>client-loss-89</td><td>████▇▇▇█▆▅████▆▅▇▇▄▄████▇▇▇█▆▅████▆▄▇█▂▁</td></tr><tr><td>client-loss-9</td><td>█▇▆▇█▇▅▇█▇▆▇█▇▅▄██▆▆█▇▃▁▇██▃█▇█▁▇▇█▂█▇█▁</td></tr><tr><td>client-loss-90</td><td>▅▅▅▅▅▅▅▅▄▂█▅▅▅▄▃▆▅▃▁</td></tr><tr><td>client-loss-91</td><td>▅▅▅▅▅▅▅▅▄▄▅▅▅▅▃▂▇▅▃▂▅▅▅▅▅▄▅▅▃▂█▅▅▅▄▃▅▅▃▁</td></tr><tr><td>client-loss-92</td><td>▅▅▅▅▅▅▅▅▄▃▅▅▅▅▃▂▇▅▄▃▅▅▅▅▅▄▅▅▃▁█▅▅▅▄▃▅▅▃▁</td></tr><tr><td>client-loss-93</td><td>▄▄▄▄▄▄▄▄▃▃▄▄▄▄▃▂▄▄▂▁▄▄▄▄▄▃▄▄▂▁█▄▄▄▄▃▄▄▃▃</td></tr><tr><td>client-loss-94</td><td>▅▅▅▅▅▄▅▅▄▄▅▅▅▅▃▃▅▅▃▂▅▅▅▅▅▄▅▅▃▂▆▅▅▅▃▁█▅▂▁</td></tr><tr><td>client-loss-95</td><td>▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅▆▆▅▄▆▆▆▆▆▆▆▆▅▃█▆▆▆▅▄▆▅▃▁</td></tr><tr><td>client-loss-97</td><td>▇▇▇▇▇▇▇▇▇▆▇▇▇▇▆▆▇▇▅▅▇▇▇▇▇▇▇▇▆▆▇█▇▇▅▄█▇▄▁</td></tr><tr><td>client-loss-98</td><td>▄▄▄▄▄▄▄▄▄▃▄▄▄▄▄▃▄▅▃▁▄▄▄▄▄▃▄▅▃▁█▄▄▄▄▄▄▄▃▃</td></tr><tr><td>client-loss-99</td><td>▃▃▃▃▃▄▃▁█▃▃▃▃▃▂▄▃▁█▃▃▃▃▄▂█▃▃▃▂▃▃▃▅▂▅▃▂▆▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
              "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>client-loss-0</td><td>1.67262</td></tr><tr><td>client-loss-1</td><td>1.48022</td></tr><tr><td>client-loss-10</td><td>1.2643</td></tr><tr><td>client-loss-11</td><td>0.6838</td></tr><tr><td>client-loss-12</td><td>1.6971</td></tr><tr><td>client-loss-13</td><td>1.90821</td></tr><tr><td>client-loss-15</td><td>1.13326</td></tr><tr><td>client-loss-16</td><td>1.78265</td></tr><tr><td>client-loss-17</td><td>0.7658</td></tr><tr><td>client-loss-19</td><td>1.00165</td></tr><tr><td>client-loss-2</td><td>1.88298</td></tr><tr><td>client-loss-20</td><td>1.26568</td></tr><tr><td>client-loss-21</td><td>0.99428</td></tr><tr><td>client-loss-22</td><td>1.12421</td></tr><tr><td>client-loss-23</td><td>0.86605</td></tr><tr><td>client-loss-24</td><td>0.92132</td></tr><tr><td>client-loss-26</td><td>0.8826</td></tr><tr><td>client-loss-27</td><td>1.40251</td></tr><tr><td>client-loss-28</td><td>1.4998</td></tr><tr><td>client-loss-29</td><td>1.09166</td></tr><tr><td>client-loss-3</td><td>1.46746</td></tr><tr><td>client-loss-30</td><td>1.19257</td></tr><tr><td>client-loss-31</td><td>1.84476</td></tr><tr><td>client-loss-32</td><td>0.83807</td></tr><tr><td>client-loss-33</td><td>0.92559</td></tr><tr><td>client-loss-34</td><td>1.88237</td></tr><tr><td>client-loss-36</td><td>1.78994</td></tr><tr><td>client-loss-37</td><td>1.11309</td></tr><tr><td>client-loss-38</td><td>1.1202</td></tr><tr><td>client-loss-39</td><td>1.6381</td></tr><tr><td>client-loss-4</td><td>0.93976</td></tr><tr><td>client-loss-40</td><td>1.04746</td></tr><tr><td>client-loss-42</td><td>1.12981</td></tr><tr><td>client-loss-43</td><td>1.93498</td></tr><tr><td>client-loss-44</td><td>1.98678</td></tr><tr><td>client-loss-45</td><td>1.20079</td></tr><tr><td>client-loss-46</td><td>0.77979</td></tr><tr><td>client-loss-47</td><td>0.66666</td></tr><tr><td>client-loss-48</td><td>0.90146</td></tr><tr><td>client-loss-5</td><td>1.34032</td></tr><tr><td>client-loss-50</td><td>0.35655</td></tr><tr><td>client-loss-51</td><td>1.67271</td></tr><tr><td>client-loss-52</td><td>1.02015</td></tr><tr><td>client-loss-53</td><td>0.82175</td></tr><tr><td>client-loss-54</td><td>1.25223</td></tr><tr><td>client-loss-55</td><td>1.5678</td></tr><tr><td>client-loss-56</td><td>0.64727</td></tr><tr><td>client-loss-57</td><td>1.08904</td></tr><tr><td>client-loss-58</td><td>0.98603</td></tr><tr><td>client-loss-6</td><td>0.76057</td></tr><tr><td>client-loss-60</td><td>1.48201</td></tr><tr><td>client-loss-61</td><td>1.70569</td></tr><tr><td>client-loss-62</td><td>1.15486</td></tr><tr><td>client-loss-63</td><td>1.90095</td></tr><tr><td>client-loss-64</td><td>0.65119</td></tr><tr><td>client-loss-65</td><td>0.81215</td></tr><tr><td>client-loss-66</td><td>1.1718</td></tr><tr><td>client-loss-67</td><td>0.90633</td></tr><tr><td>client-loss-68</td><td>1.32141</td></tr><tr><td>client-loss-69</td><td>1.54787</td></tr><tr><td>client-loss-7</td><td>0.75578</td></tr><tr><td>client-loss-70</td><td>1.05146</td></tr><tr><td>client-loss-72</td><td>1.04441</td></tr><tr><td>client-loss-73</td><td>1.88615</td></tr><tr><td>client-loss-76</td><td>1.23699</td></tr><tr><td>client-loss-77</td><td>0.46656</td></tr><tr><td>client-loss-78</td><td>1.50565</td></tr><tr><td>client-loss-79</td><td>1.21649</td></tr><tr><td>client-loss-8</td><td>1.12838</td></tr><tr><td>client-loss-80</td><td>1.92086</td></tr><tr><td>client-loss-82</td><td>1.83542</td></tr><tr><td>client-loss-83</td><td>0.80589</td></tr><tr><td>client-loss-84</td><td>1.65011</td></tr><tr><td>client-loss-85</td><td>1.73368</td></tr><tr><td>client-loss-86</td><td>1.15383</td></tr><tr><td>client-loss-87</td><td>1.78126</td></tr><tr><td>client-loss-89</td><td>1.63342</td></tr><tr><td>client-loss-9</td><td>1.49556</td></tr><tr><td>client-loss-90</td><td>0.71359</td></tr><tr><td>client-loss-91</td><td>0.60838</td></tr><tr><td>client-loss-92</td><td>0.51911</td></tr><tr><td>client-loss-93</td><td>1.82143</td></tr><tr><td>client-loss-94</td><td>1.2317</td></tr><tr><td>client-loss-95</td><td>0.30872</td></tr><tr><td>client-loss-97</td><td>0.71435</td></tr><tr><td>client-loss-98</td><td>1.51673</td></tr><tr><td>client-loss-99</td><td>1.45825</td></tr></table>\n",
              "</div></div>\n",
              "Synced 5 W&B file(s), 100 media file(s), 0 artifact file(s) and 1 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">comic-violet-41</strong>: <a href=\"https://wandb.ai/aml-federated-learning/step-2/runs/x40uwyvc\" target=\"_blank\">https://wandb.ai/aml-federated-learning/step-2/runs/x40uwyvc</a><br/>\n",
              "Find logs at: <code>./wandb/run-20211229_090648-x40uwyvc/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "timestr = time.strftime(\"%Y_%m_%d-%I_%M_%S_%p\")\n",
        "artifact_filename = f\"artifacts/server_model-{timestr}.pth\"\n",
        "\n",
        "# parameters of the trained model\n",
        "server_model = net.state_dict()\n",
        "# save the model on the local file system\n",
        "torch.save(server_model, artifact_filename)\n",
        "# save the model on wandb\n",
        "wandb.save(artifact_filename)\n",
        "\n",
        "# Finish the wandb session and upload all data\n",
        "wandb.finish(0, quiet=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "aml.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8b88bd330db6447ab67a1ab1eaa1e8a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d1d26613fae14b55ba58e93089f74cbd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2856de2329954b77aa190e7fa6cfba5f",
              "IPY_MODEL_39bfea5fd5134fcab9c13cc06c6ad443"
            ]
          }
        },
        "d1d26613fae14b55ba58e93089f74cbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2856de2329954b77aa190e7fa6cfba5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_e6be789085b74552a74d333e807ff3ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.55MB of 0.55MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_01461636fc5945a9b70a375614104961"
          }
        },
        "39bfea5fd5134fcab9c13cc06c6ad443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_011eb236e2df4a64a79e637685a6a3fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a81b7e73924d4bcf89495124dc5bf1b9"
          }
        },
        "e6be789085b74552a74d333e807ff3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "01461636fc5945a9b70a375614104961": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "011eb236e2df4a64a79e637685a6a3fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a81b7e73924d4bcf89495124dc5bf1b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}