{"cells":[{"cell_type":"markdown","metadata":{"id":"KRyFWIxiPEVX"},"source":["# Baseline implementation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# download the Cifar10 non-iid splits, if not present\n","\n","from os import path\n","import urllib.request\n","import zipfile\n","\n","if not path.exists(\"cifar10\"):\n","    save_path = \"cifar10.zip\"\n","    urllib.request.urlretrieve(\"http://storage.googleapis.com/gresearch/federated-vision-datasets/cifar10_v1.1.zip\", save_path)\n","    \n","    with zipfile.ZipFile(save_path, 'r') as zip_ref:\n","        zip_ref.extractall(\"cifar10\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["config = {\n","    \"E\": 1, # number of local epochs\n","    \"K\": 5, # number of clients selected each round # [5, 10, 20]\n","    \"NUMBER_OF_CLIENTS\": 100, # total number of clients\n","    \"MAX_TIME\": 5000,\n","    \"BATCH_SIZE\": 50,\n","    \"VALIDATION_BATCH_SIZE\": 500,\n","    \"LR\": 0.01,\n","    \"WEIGHT_DECAY\": 4e-4,\n","    \"DATA_DISTRIBUTION\": \"non-iid\", # \"iid\" | \"non-iid\"\n","    \"DIRICHELET_ALPHA\": [0.00, 0.05, 0.10, 0.20, 0.50, 1.00, 10.00, 100.0],\n","    \"AVERAGE_ACCURACY\": np.zeros(8),\n","    \"FED_AVG_M\": False,\n","    \"FED_AVG_M_BETA\": 0.9,\n","    \"FED_AVG_M_GAMMA\": 1,\n","    \"LR_DECAY\": 0.99,\n","    \"LOG_FREQUENCY\": 25,\n","    \"AUGMENTATION_PROB\": 0.0,\n","    \"SAVE_FREQUENCY\": 100,\n","    \"NORM_LAYER\": \"\", # batch normalization\n","}\n","\n","use_data_preloading = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Ar1b6p68b3G","outputId":"e695f455-87f7-44c6-fe6f-fb6bdf6b300d","trusted":true},"outputs":[],"source":["import torch.optim as optim\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","# From: https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        \n","        self.conv1 = nn.Conv2d(3, 64, 5)\n","        if config[\"NORM_LAYER\"] == \"bn\":\n","            self.norm1 = nn.BatchNorm2d(64)\n","        elif config[\"NORM_LAYER\"] == \"gn\":\n","            self.norm1 = nn.GroupNorm(4, 64)\n","        \n","        self.conv2 = nn.Conv2d(64, 64, 5)\n","        if config[\"NORM_LAYER\"] == \"bn\":\n","            self.norm2 = nn.BatchNorm2d(64)\n","        elif config[\"NORM_LAYER\"] == \"gn\":\n","            self.norm2 = nn.GroupNorm(4, 64)\n","        \n","        self.fc1 = nn.Linear(64 * 5 * 5, 384)\n","        self.fc2 = nn.Linear(384, 192)\n","        self.fc3 = nn.Linear(192, 10)\n","\n","    def forward(self, x):\n","        if config[\"NORM_LAYER\"] in ['bn', 'gn']:\n","            x = F.max_pool2d(F.relu(self.norm1(self.conv1(x))), (2,2))\n","            x = F.max_pool2d(F.relu(self.norm2(self.conv2(x))), 2)\n","        else:\n","            x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n","            x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n","        \n","        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","        \n","#print(net)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eCwGFjE5Feil","trusted":true},"outputs":[],"source":["import torch.optim as optim\n","\n","class Client:\n","    def __init__(self, i, train_set, validation_set, *, input_size=32, use_data_preloading, train_transform):\n","        self.i = i\n","        self.net = Net()\n","        self.net = self.net.to(device)\n","        \n","        # Create the validation loader\n","        self.validation_loader = torch.utils.data.DataLoader(validation_set,\n","            batch_size=len(validation_set),\n","            shuffle=False, num_workers=0\n","        )\n","        \n","        # Create an optimizer for the model's parameters\n","        self.optimizer = optim.SGD(self.net.parameters(), lr=config[\"LR\"], weight_decay=config[\"WEIGHT_DECAY\"])\n","        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n","        \n","        self.train_transform = train_transform\n","\n","        self.use_data_preloading = use_data_preloading\n","        if self.use_data_preloading:\n","            # preloading train and validation data\n","            self.train_loader = torch.utils.data.DataLoader(train_set,\n","                batch_size=len(train_set), shuffle=True, \n","                num_workers=0, pin_memory=True\n","            )\n","            \n","            # preload the training images\n","            training_images, training_labels = next(iter(self.train_loader))\n","            self.training_images = training_images.to(device)\n","            self.training_labels = training_labels.to(device)\n","            \n","            # preload the validation images\n","            validation_images, validation_labels = next(iter(self.validation_loader))\n","            self.validation_images = validation_images.to(device)\n","            self.validation_labels = validation_labels.to(device)\n","        else:\n","            self.train_loader = torch.utils.data.DataLoader(train_set, \n","                batch_size=config[\"BATCH_SIZE\"], shuffle=True, \n","                num_workers=0, pin_memory=True\n","            )\n","\n","    def clientUpdate(self, lr, parameters):\n","        self.net.load_state_dict(parameters)\n","        self.net.train()\n","\n","        for g in self.optimizer.param_groups:\n","            g[\"lr\"] = lr\n","\n","        for _ in range(config[\"E\"]):\n","            epoch_loss, n = 0, 0\n","            for images, labels in self.iter_training_data():\n","                # in your training loop:\n","                self.optimizer.zero_grad()  # zero the gradient buffers\n","                outputs = self.net(images)\n","                loss = self.criterion(outputs, labels)\n","                epoch_loss += loss\n","                n += labels.size(0)\n","\n","                loss = loss / labels.size(0)\n","                loss.backward()\n","                # wandb.log({f\"client-loss-{self.i}\": loss.item()})\n","                self.optimizer.step()  # Does the update\n","            epoch_loss = epoch_loss / n\n","\n","        return_dict = {}\n","        for (k1, v1), (k2, v2) in zip(parameters.items(), self.net.state_dict().items()):\n","            return_dict[k1] = v1 - v2\n","        return epoch_loss, return_dict\n","\n","    def iter_training_data(self):\n","        batch_size = config[\"BATCH_SIZE\"]\n","\n","        if self.use_data_preloading:\n","            # shuffle the training data\n","            indices = torch.randperm(self.training_images.size(0))\n","            training_images, training_labels = self.training_images[indices], self.training_labels[indices]\n","            \n","            # possibly apply the training transformation\n","            if self.train_transform is not None:\n","                training_images = torch.stack([self.train_transform(im) for im in training_images])\n","            \n","            yield from zip(torch.split(training_images, batch_size), torch.split(training_labels, batch_size))\n","        else:\n","            yield from self.train_loader\n","                \n","    def iter_validation_data(self):\n","        batch_size = config[\"VALIDATION_BATCH_SIZE\"]\n","\n","        if self.use_data_preloading:\n","            yield from zip(torch.split(self.validation_images, batch_size), torch.split(self.validation_labels, batch_size))\n","        else:\n","            yield from self.validation_loader\n","\n","    def compute_accuracy(self, parameters):\n","        self.net.load_state_dict(parameters)\n","        self.net.eval()\n","\n","        running_corrects = 0\n","        loss, n = 0, 0\n","        for data, labels in self.iter_validation_data():\n","            with torch.no_grad():\n","                outputs = self.net(data)\n","            loss += self.criterion(outputs, labels).item()\n","\n","            _, preds = torch.max(outputs.data, 1)\n","\n","            running_corrects += torch.sum(preds == labels.data).data.item()\n","            n += len(preds)\n","\n","        return loss / n, running_corrects / n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QcsNecZCVPP-","trusted":true},"outputs":[],"source":["from collections import defaultdict\n","\n","def parse_csv(filename):\n","  splits = defaultdict(lambda: [])\n","  labels_mapping = dict()\n","\n","  with open(filename) as f:\n","    for line in f:\n","      if not line[0].isdigit():\n","        continue\n","\n","      user_id, image_id, label = (int(token) for token in line.split(\",\"))\n","      splits[user_id].append(image_id)\n","      labels_mapping[image_id] = label\n","\n","  return splits, labels_mapping"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import time\n","import json\n","import numpy\n","from copy import deepcopy\n","\n","def listToString(l): \n","    return \" \".join(str(l))\n","\n","def printJSON(alpha, acc, net, step = None):\n","    artifacts_dir = \"artifacts\"\n","\n","    artifact_filename = f\"ALPHA_{alpha}_E_{config['E']}_K_{config['K']}\"\n","    if step is not None:\n","      artifact_filename += f\"_STEPS_{step}\"\n","    \n","    if config[\"AUGMENTATION_PROB\"] > 0:\n","      artifact_filename += f\"_T\"\n","\n","    artifact_filename += f\"_{config['NORM_LAYER'].upper()}\" if config['NORM_LAYER'] else \"\"\n","      \n","    # parameters of the trained model\n","    server_model = net.state_dict()\n","    # save the model on the local file system\n","    torch.save(server_model, f\"{artifacts_dir}/{artifact_filename}.pth\")\n","    config_copy = deepcopy(config)\n","    config_copy[\"DIRICHELET_ALPHA\"] = listToString(config_copy[\"DIRICHELET_ALPHA\"])\n","    config_copy[\"AVERAGE_ACCURACY\"] = numpy.array2string(config_copy[\"AVERAGE_ACCURACY\"])\n","    data = {\n","        \"config\": config_copy,\n","        \"alpha\": listToString(alpha),\n","        \"accuracy\": acc\n","    }\n","\n","    with open(f\"{artifacts_dir}/{artifact_filename}.json\", \"w\") as f:\n","        f.write(json.dumps(data, indent=4))\n","\n","    # If you want to cat the file, my suggestion is to avoid this is a pretty heavy operation at least on my pc\n","    #artifact_filename += \".json\"\n","    #!cat artifact_filename\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def selectClients(k):\n","  return random.sample(clients, k=k)\n","\n","def aggregateClient(deltaThetas):\n","  parameters = None\n","  for i,d in enumerate(deltaThetas):\n","    #ratio = len(trainsets[i])/len(trainset)\n","    ratio = len(trainsets[i])/(len(trainsets[i])*config['K'])\n","    \n","    if i == 0:\n","      parameters = {k:ratio*v for k, v in d.items()}\n","    else:\n","      for (k, v) in d.items():\n","        parameters[k] += ratio * v\n","   \n","  return parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gTmw78eJ-EW5","outputId":"9bad269e-aa08-45ed-f934-27c805e12b15","trusted":true},"outputs":[],"source":["import torchvision\n","import torchvision.transforms as transforms\n","import numpy as np\n","import random\n","from statistics import mean\n","\n","from tqdm.notebook import tqdm\n","\n","import os\n","\n","random.seed(42)\n","\n","# Random transformations that provide data augmentation\n","random_transform = transforms.Compose(\n","    [\n","        transforms.RandomCrop(32, padding=4),\n","        transforms.RandomHorizontalFlip(1),\n","        transforms.ColorJitter(0.9, 0.9)\n","    ]\n",")\n","# Normalization values for the CIFAR10 dataset\n","normalization_transform = transforms.Normalize(\n","    mean=[0.491, 0.482, 0.447], \n","    std=[0.247, 0.243, 0.262]\n",")\n","\n","# Transformation strategy:\n","#  1. apply as many transformations as possibile offline (at trainset level)\n","#  2. apply the remaining transformations online (at client level, before\n","#     iterating over the data)\n","#  \n","# Random transformations must be applied online.\n","\n","if use_data_preloading:\n","    # data preloading is enabled\n","    \n","    if config[\"AUGMENTATION_PROB\"] > 1e-5:\n","        # non-zero augmentation probability => apply transformations online\n","        offline_train_transform = None\n","        online_train_transform = transforms.Compose([\n","            transforms.RandomApply([random_transform], config[\"AUGMENTATION_PROB\"]),\n","            normalization_transform\n","        ])\n","    else:\n","        # zero augmentation probability => apply transformations offline\n","        offline_train_transform = normalization_transform\n","        online_train_transform = None\n","else:\n","    # augmentation probability is zero => all transformations can be applied offline\n","    offline_train_transform = transforms.Compose([\n","        transforms.RandomApply([random_transform], config[\"AUGMENTATION_PROB\"]),\n","        normalization_transform\n","    ])\n","    online_train_transform = None\n","    \n","\n","trainset = torchvision.datasets.CIFAR10(\n","    root='./data', \n","    train=True,\n","    download=True, \n","    transform=transforms.Compose([transforms.ToTensor(), offline_train_transform])\n",")\n","\n","testset = torchvision.datasets.CIFAR10(\n","    root='./data', \n","    train=False,\n","    download=True, \n","    transform=transforms.Compose([transforms.ToTensor(), normalization_transform])\n","  )\n","\n","if not path.exists(\"artifacts\"):\n","  os.mkdir(\"artifacts\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# verify the labels specified in the .csv files are coherent with the actual CIFAR-10 labels\n","# see https://github.com/google-research/google-research/issues/924\n","\n","_, labels_mapping = parse_csv(f\"cifar10/federated_train_alpha_{0.0:.2f}.csv\")\n","assert(all(label == labels_mapping[idx] for idx, label in enumerate(trainset.targets)))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for alpha_i, alpha in enumerate(config[\"DIRICHELET_ALPHA\"]):\n","  net = Net()\n","  net = net.to(device)\n","\n","  optimizer = optim.SGD(net.parameters(), lr=config[\"LR\"], momentum=0.9, weight_decay=1e-3)\n","  scheduler = ReduceLROnPlateau(optimizer, \"min\", factor=0.5, min_lr=1e-6, verbose=True)\n","\n","  if config[\"DATA_DISTRIBUTION\"] == \"iid\":\n","    # split the training set\n","    trainset_len = ( len(trainset) // config[\"NUMBER_OF_CLIENTS\"] ) * config[\"NUMBER_OF_CLIENTS\"]\n","    trainset = torch.utils.data.Subset(trainset, list(range(trainset_len)))\n","\n","    lengths = len(trainset) // config[\"NUMBER_OF_CLIENTS\"] * np.ones(config[\"NUMBER_OF_CLIENTS\"], dtype=int)\n","    trainsets = torch.utils.data.random_split(dataset=trainset, lengths=lengths)\n","  else:\n","    dirichelet_splits, _ = parse_csv(f\"cifar10/federated_train_alpha_{alpha:.2f}.csv\")\n","    trainsets = [torch.utils.data.Subset(trainset, indices) for indices in dirichelet_splits.values()]\n","\n","\n","  # split the validation set\n","  testset_len = ( len(testset) // config[\"NUMBER_OF_CLIENTS\"] ) * config[\"NUMBER_OF_CLIENTS\"]\n","  testset = torch.utils.data.Subset(testset, list(range(testset_len)))\n","\n","  lengths = len(testset) // config[\"NUMBER_OF_CLIENTS\"] * np.ones(config[\"NUMBER_OF_CLIENTS\"], dtype=int)\n","  testsets = torch.utils.data.random_split(dataset=testset, lengths=lengths)\n","\n","\n","  clientsSizes = torch.zeros(config[\"NUMBER_OF_CLIENTS\"])\n","  clients = list()\n","\n","  for c in range(config[\"NUMBER_OF_CLIENTS\"]):\n","    clients.append(Client(c, trainsets[c], testsets[c], use_data_preloading=use_data_preloading, train_transform=online_train_transform))\n","\n","  if config[\"FED_AVG_M\"]:\n","    old_parameters = {}\n","\n","  # collect the test accuracies over the epochs\n","  test_accuracies = []\n","\n","  accuracies = list()\n","\n","  # best model\n","  best_model = {}\n","  best_accuracy = 0.0\n","\n","  for step in tqdm(range(config[\"MAX_TIME\"])):\n","    selected_clients = selectClients(config[\"K\"])\n","    #print(f\"Client(s) {[client.i for client in selected_clients]} selected\")\n","\n","    deltaThetas = list()\n","    losses = list()\n","    for i, c in enumerate(selected_clients):\n","      loss, parameters = c.clientUpdate(optimizer.param_groups[0]['lr'], net.state_dict())\n","      deltaThetas.append(parameters)\n","      losses.append(loss)\n","\n","    g = aggregateClient(deltaThetas)\n","    \n","    parameters = {}\n","    for (k1, v1), (k2, v2) in zip(net.state_dict().items(), g.items()):\n","      \n","      if config[\"FED_AVG_M\"]:\n","        if k1 in old_parameters:\n","          parameters[k1] = v1 - config[\"FED_AVG_M_GAMMA\"] * (config[\"FED_AVG_M_BETA\"] * old_parameters[k1] + v2)  \n","          old_parameters[k1] = config[\"FED_AVG_M_BETA\"] * old_parameters[k1] + v2\n","        else:\n","          parameters[k1] = v1 - config[\"FED_AVG_M_GAMMA\"] * v2\n","          old_parameters[k1] = v2\n","      else:\n","        parameters[k1] = v1 - v2 # todo: add server learning rate gamma\n","\n","    # compute loss and accuracy on the test set of the clients\n","    # client.compute_accuracy(parameters) returns tuples (loss, accuracy)\n","    # client_losses_accuracies = [client.compute_accuracy(parameters) for client in clients]\n","    # client_losses, client_accuracies = zip(*client_losses_accuracies)\n","\n","    # compute the average client loss\n","    # and feed it to the scheduler\n","    # avg_client_loss = mean(client_loss for client_loss in client_losses)\n","    # scheduler.step(avg_client_loss)\n","\n","    # compute the average accuracy\n","    if step % config[\"LOG_FREQUENCY\"] == 0:\n","      client_losses_accuracies = [client.compute_accuracy(parameters) for client in clients]\n","      client_losses, client_accuracies = zip(*client_losses_accuracies)\n","      \n","      avg_client_accuracy = mean(client_acc for client_acc in client_accuracies)\n","      accuracies.append(avg_client_accuracy * 100)\n","      \n","      if avg_client_accuracy >= best_accuracy:\n","        best_accuracy = avg_client_accuracy\n","        best_model = deepcopy(parameters) # net.state_dict()\n","          \n","      print(f\"Average accuracy after {step} rounds is {avg_client_accuracy*100:.2f}\")    \n","\n","    net.load_state_dict(parameters)\n","\n","    if step % config[\"SAVE_FREQUENCY\"] == 0:\n","      printJSON(alpha, accuracies, net, step)\n","  \n","  avg_accuracy = mean(float(client.compute_accuracy(best_model)[1]) for client in clients)\n","  #model_parameters = net.state_dict()\n","  #avg_accuracy = mean(float(client.compute_accuracy(model_parameters)[1]) for client in clients)\n"," \n","  #alpha = config[\"DIRICHELET_ALPHA\"][i]\n","  config[\"AVERAGE_ACCURACY\"][alpha_i] = avg_accuracy\n","  print(f\"Average accuracy with alpha = {alpha} after {step+1} rounds is {avg_accuracy*100:.2f}\")\n","  printJSON(alpha, accuracies, net)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import shutil\n","shutil.make_archive('artifacts', 'zip', 'artifacts')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"}},"nbformat":4,"nbformat_minor":4}
