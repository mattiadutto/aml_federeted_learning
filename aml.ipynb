{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aml.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "57dfccecdec74aa89fb417eb0f27abb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0be5eccb82c44c15b09c6b1e4cc336be",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1bde181cd6d9497e875a03c9a13cb76c",
              "IPY_MODEL_c26bb12eb9574e21978bfa3ade92f447"
            ]
          }
        },
        "0be5eccb82c44c15b09c6b1e4cc336be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1bde181cd6d9497e875a03c9a13cb76c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_f42189b153f340d69a2a261549f63927",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.08MB of 0.08MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bff43fb1980d442881df1f4176841fda"
          }
        },
        "c26bb12eb9574e21978bfa3ade92f447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_185d5ea25b024ad6bc3d713dbeabfa2a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b82bfc8ad63f437fb4912bdeff1cdf3f"
          }
        },
        "f42189b153f340d69a2a261549f63927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bff43fb1980d442881df1f4176841fda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "185d5ea25b024ad6bc3d713dbeabfa2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b82bfc8ad63f437fb4912bdeff1cdf3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN9_GO3YcGI9",
        "outputId": "76caaaf4-36c8-413e-a429-b308467d3140"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.9-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.1-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 46.5 MB/s \n",
            "\u001b[?25hCollecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 44.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=0e25e62280e52be3fd02fc2a425ef6c2618775b8566ce506b014373d0477857f\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=d0220563d8bf63f2e827ce990e9b423d3f8435a64c968ec4b3e4b78d98b82902\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n",
            "Successfully installed GitPython-3.1.24 configparser-5.2.0 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.1 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.9 yaspin-2.1.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "Aborted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init(project=\"step-2\", entity=\"aml-federated-learning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329,
          "referenced_widgets": [
            "57dfccecdec74aa89fb417eb0f27abb2",
            "0be5eccb82c44c15b09c6b1e4cc336be",
            "1bde181cd6d9497e875a03c9a13cb76c",
            "c26bb12eb9574e21978bfa3ade92f447",
            "f42189b153f340d69a2a261549f63927",
            "bff43fb1980d442881df1f4176841fda",
            "185d5ea25b024ad6bc3d713dbeabfa2a",
            "b82bfc8ad63f437fb4912bdeff1cdf3f"
          ]
        },
        "id": "X82NHRCAcXLl",
        "outputId": "3884021d-3bf1-498b-dbf9-2cfe9a78f4ae"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:3r7td4mx) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 3605... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57dfccecdec74aa89fb417eb0f27abb2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>client-loss-0</td><td>▅▃▅▅▄▂▆▆▃▄▃▃▃▄▇▃▄▂▅▁▄▄▅▅▁▆▇▇▂▆▂▅▂▅▃█▄▄▇▄</td></tr><tr><td>client-loss-2</td><td>▆▃▅▄▁▅▅▄▂▅▅▄▅▄▃▄▄▅▆▄▄▆▄█▄▄▅▃▆▅▄▆▅▃▅▅▅▄▇▅</td></tr><tr><td>client-loss-6</td><td>▆▅▇▆▇▄▇▆▄▆▂▇█▅█▄▇▃▆▆▆▇▃▆▄▂▅█▃▇▅▅▆▇▃▁▅▂▃▃</td></tr><tr><td>client-loss-7</td><td>▄▇▄▄▃▄▄▅▅▃▄▅▆▄▄▅▄▁▅▇▆█▄▇▂▅▆▁▃▁▆▇▅▂▅▆▅▅▆▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
              "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>client-loss-0</td><td>2.32543</td></tr><tr><td>client-loss-2</td><td>2.35955</td></tr><tr><td>client-loss-6</td><td>2.31227</td></tr><tr><td>client-loss-7</td><td>2.34865</td></tr></table>\n",
              "</div></div>\n",
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">eager-totem-15</strong>: <a href=\"https://wandb.ai/aml-federated-learning/step-2/runs/3r7td4mx\" target=\"_blank\">https://wandb.ai/aml-federated-learning/step-2/runs/3r7td4mx</a><br/>\n",
              "Find logs at: <code>./wandb/run-20211227_112541-3r7td4mx/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Successfully finished last run (ID:3r7td4mx). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/aml-federated-learning/step-2/runs/2o9lran7\" target=\"_blank\">eager-shadow-16</a></strong> to <a href=\"https://wandb.ai/aml-federated-learning/step-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fe6f5159250>"
            ],
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/aml-federated-learning/step-2/runs/2o9lran7?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "E = 2\n",
        "STEP_SIZE = 5\n",
        "GAMMA = 0.1\n",
        "\n",
        "# K = 1, NUMBE_OR_CLIENTS = 2, MAX_TIME = 3 -> 58 sec\n",
        "\n",
        "K = 1 # to set\n",
        "NUMBER_OF_CLIENTS = 10 # to set\n",
        "MAX_TIME = 5 #to set\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "lr = 1e-3\n",
        "\n",
        "wandb.config.update({\n",
        "    \"batch-size\": batch_size,\n",
        "    \"learning-rate\": lr,\n",
        "    # \"momentum\": MOMENTUM,\n",
        "    # \"weight_decay\": WEIGHT_DECAY,\n",
        "    \"num_epochs\": E,\n",
        "    \"step_size\": STEP_SIZE,\n",
        "    \"gamma\": GAMMA,\n",
        "    \"K\": K,\n",
        "    \"number_of_clients\": NUMBER_OF_CLIENTS,\n",
        "    \"max_time\": MAX_TIME\n",
        "})"
      ],
      "metadata": {
        "id": "ww5uiZ6HfmBd"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ar1b6p68b3G",
        "outputId": "ecc5ab3e-d157-4b88-eb75-2d0e15833c13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# From: https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square, you can specify with a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net = net.to(\"cuda\")\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "class Client():\n",
        "  def __init__(self, i, train_set, validation_set):\n",
        "    self.i = i\n",
        "    self.train_set = train_set\n",
        "    self.batch_size = 32\n",
        "    self.train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "    self.validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "    self.net = Net()\n",
        "    self.net = self.net.to(\"cuda\")\n",
        "    wandb.watch(self.net, log_freq=10)\n",
        "    # create your optimizer\n",
        "    self.optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "    self.criterion = nn.CrossEntropyLoss()\n",
        "    self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "    \n",
        "  def clientUpdate(self, parameters):\n",
        "    self.net.load_state_dict(parameters)\n",
        "    theta = parameters\n",
        "    for e in range(E):\n",
        "      for images, labels in self.train_loader:\n",
        "        images = images.to(\"cuda\")\n",
        "        labels = labels.to(\"cuda\")\n",
        "        # in your training loop:\n",
        "        self.optimizer.zero_grad()   # zero the gradient buffers\n",
        "        output = self.net(images)\n",
        "        loss = self.criterion(output, labels)\n",
        "        loss.backward()\n",
        "        wandb.log({f\"client-loss-{self.i}\": loss.item()})\n",
        "        self.optimizer.step()    # Does the update\n",
        "    \n",
        "    return_dict = {}\n",
        "    for (k1, v1), (k2, v2) in zip(parameters.items(), net.state_dict().items()):\n",
        "      return_dict[k1] = v1 - lr * v2\n",
        "    return return_dict\n",
        "\n",
        "  def compute_accuracy(self, parameters):\n",
        "    self.net.load_state_dict(parameters)\n",
        "\n",
        "    running_corrects = 0\n",
        "    n = 0\n",
        "    for data, labels in self.validation_loader:\n",
        "        data = data.to(\"cuda\")\n",
        "        labels = labels.to(\"cuda\")\n",
        "\n",
        "        outputs = self.net(data)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        n += len(preds)\n",
        "                \n",
        "    return running_corrects / n\n"
      ],
      "metadata": {
        "id": "eCwGFjE5Feil"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform = transform)\n",
        "\n",
        "\n",
        "# split the training set\n",
        "trainset_len = ( len(trainset) // NUMBER_OF_CLIENTS ) * NUMBER_OF_CLIENTS\n",
        "print(trainset_len)\n",
        "trainset = torch.utils.data.Subset(trainset, list(range(trainset_len)))\n",
        "\n",
        "lengths = len(trainset) // NUMBER_OF_CLIENTS * np.ones(NUMBER_OF_CLIENTS, dtype=np.int)\n",
        "print(lengths)\n",
        "trainsets = torch.utils.data.random_split(dataset=trainset, lengths=lengths)\n",
        "\n",
        "# split the validation set\n",
        "testset_len = ( len(testset) // NUMBER_OF_CLIENTS ) * NUMBER_OF_CLIENTS\n",
        "print(testset_len)\n",
        "testset = torch.utils.data.Subset(testset, list(range(testset_len)))\n",
        "\n",
        "lengths = len(testset) // NUMBER_OF_CLIENTS * np.ones(NUMBER_OF_CLIENTS, dtype=np.int)\n",
        "# print(lengths)\n",
        "testsets = torch.utils.data.random_split(dataset=testset, lengths=lengths)\n",
        "\n",
        "clientsSizes = torch.zeros(NUMBER_OF_CLIENTS)\n",
        "clients = list()\n",
        "\n",
        "def selectClients(k):\n",
        "  return random.choices(clients, k=k)\n",
        "\n",
        "def aggregateClient(deltaThetas):\n",
        "  parameters = None\n",
        "  for i,d in enumerate(deltaThetas):\n",
        "    if i == 0:\n",
        "      parameters = d\n",
        "    else:\n",
        "      for (k, v) in d.items():\n",
        "        parameters[k] += len(trainsets[i])/len(trainset) * v\n",
        "   \n",
        "  return parameters\n",
        "\n",
        "for c in range(NUMBER_OF_CLIENTS):\n",
        "  clients.append(Client(c, trainsets[c], testsets[c]))\n",
        "\n",
        "\n",
        "for t in range(MAX_TIME):\n",
        "  selected_clients = selectClients(K)\n",
        "  print(f\"Client {selected_clients[0].i} selected\")\n",
        "  deltaThetas = list()\n",
        "  for i, c in enumerate(selected_clients):\n",
        "    deltaThetas.append(c.clientUpdate(net.state_dict()))\n",
        "  g = aggregateClient(deltaThetas)\n",
        "  \n",
        "  parameters = {}\n",
        "  for (k1, v1), (k2, v2) in zip(net.state_dict().items(), g.items()):\n",
        "    parameters[k1] = v1 - lr * v2\n",
        "  net.load_state_dict(parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTmw78eJ-EW5",
        "outputId": "eef3d25f-5447-4558-f709-b2bf59d000f9"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "50000\n",
            "[5000 5000 5000 5000 5000 5000 5000 5000 5000 5000]\n",
            "10000\n",
            "Client 6 selected\n",
            "Client 0 selected\n",
            "Client 2 selected\n",
            "Client 2 selected\n",
            "Client 7 selected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_parameters = net.state_dict()\n",
        "\n",
        "avg_accuracy = sum(client.compute_accuracy(model_parameters) for client in clients)\n",
        "avg_accuracy = avg_accuracy / NUMBER_OF_CLIENTS\n",
        "\n",
        "print(f\"Average accuracy after {MAX_TIME} rounds is {avg_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utb7E9snmQwi",
        "outputId": "07a3b5d9-784c-4b06-c27b-3502d4df06a1"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy after 5 rounds is 0.10069999999999998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4yo5tYPNmxQz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}